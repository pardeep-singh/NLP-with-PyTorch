{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31648ca5",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Advanced Sequence Modeling for Natural Language Processing<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Sequence-to-Sequence-Models,-Encoder-Decoder-Models-and-Conditioned-Generation\" data-toc-modified-id=\"Sequence-to-Sequence-Models,-Encoder-Decoder-Models-and-Conditioned-Generation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Sequence-to-Sequence Models, Encoder-Decoder Models and Conditioned Generation</a></span></li><li><span><a href=\"#Capturing-More-from-a-Sequence:-Bidirectional-Recurrent-Models\" data-toc-modified-id=\"Capturing-More-from-a-Sequence:-Bidirectional-Recurrent-Models-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Capturing More from a Sequence: Bidirectional Recurrent Models</a></span></li><li><span><a href=\"#Capturing-More-from-a-Sequence:-Attention\" data-toc-modified-id=\"Capturing-More-from-a-Sequence:-Attention-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Capturing More from a Sequence: Attention</a></span><ul class=\"toc-item\"><li><span><a href=\"#Attention-in-Deep-Neural-Networks\" data-toc-modified-id=\"Attention-in-Deep-Neural-Networks-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Attention in Deep Neural Networks</a></span></li></ul></li><li><span><a href=\"#Evaluating-Sequence-Generation-Models\" data-toc-modified-id=\"Evaluating-Sequence-Generation-Models-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Evaluating Sequence Generation Models</a></span></li><li><span><a href=\"#Example:-Neural-Machine-Translation\" data-toc-modified-id=\"Example:-Neural-Machine-Translation-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Example: Neural Machine Translation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Vocabulary,-Vectorizer-and-Dataset\" data-toc-modified-id=\"Vocabulary,-Vectorizer-and-Dataset-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Vocabulary, Vectorizer and Dataset</a></span></li><li><span><a href=\"#NMT-Model-with-No-Sampling\" data-toc-modified-id=\"NMT-Model-with-No-Sampling-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>NMT Model with No Sampling</a></span></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Evaluation</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c008ba4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068d8768",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- _Sequence-to-sequence Modeling_ refers to taking sequence as input and producing another sequence as an output of possibly different length\n",
    "- Examples\n",
    "    - Predict response for a given email\n",
    "    - Translate text\n",
    "    - Summarize the given text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087be68d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Sequence-to-Sequence Models, Encoder-Decoder Models and Conditioned Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c2de11",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- **Sequence-to-Sequence(S2S)** models are a special case of general family of models alled _encoder-decoder models_\n",
    "- Encoder-Decoder model is a composition of two models -> an Encoder and a Decoder that are trained jointly.\n",
    "    - Encoder Model takes an input and produces an encoding or a representation $(\\phi)$ of the input which is usually a vector. The goal of the encoder is to capture important properties of the input with respect to the task at hand.\n",
    "    - The goal of the decoder is to take the encoded input and produce a desired output.\n",
    "- So S2S models can be defined as encoder-decoder models in which the encoder and decoder are sequence models and the inputs and outputs are both sequences possibly of different lengths.\n",
    "\n",
    "![Figure 8.1](../images/figure_8_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8b4011",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Encoder-Decoder Models as Special Case of Conditioned Generation Models**\n",
    "\n",
    "- In Conditioned generation, instead of the input respresentation $\\phi$, a general conditioning context $c$ influences a decoder to produce an output.\n",
    "- When the conditioning context $c$ comes from an encoder model, conditioned generation is same as an encoder-decoder model.\n",
    "- Not all conditioned generation models are encoder-decoder models, because it is possible for the conditioning context to be derived from a structured source.\n",
    "- For example, in weather report generation, the value of the temperature, humidity and wind speed and direction could condition a decoder to generate the textual weather report.\n",
    "\n",
    "![Figure 8.2](../images/figure_8_2.png)\n",
    "![Figure 8.3](../images/figure_8_3.png)\n",
    "![Figure 8.4](../images/figure_8_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620c4e38",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Capturing More from a Sequence: Bidirectional Recurrent Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a290d1f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- The goal of bidirectional recurrent model is to combine the information from past and future to robustly represent the meaning of a word in a sequence.\n",
    "- Any model in the recurrent family, such as Elmann RNNs, LSTMs or GRUs could be used in such a bidirectional formulation.\n",
    "- Bidirectional models like unidirectional models can be used in both classification and sequence labeling settings.\n",
    "\n",
    "![Figure 8.5](../images/figure_8_5.png)\n",
    "![Figure 8.6](../images/figure_8_6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f8c959",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Capturing More from a Sequence: Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8b6022",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Problems with S2S, encoder-decoder and conditioned generation models**\n",
    "\n",
    "- These models crams(encodes) the entire input sentence into a single vector $\\phi$ and uses that encoding to generate the output. This might work for very short sentences but will fail to capture the information in the entire input in case of ling sentences. This is a limitation of using just the final hidden state as the encoding.\n",
    "- Gradients vanishing problem can also happen during back prooagation throigh time which makes the training difficult.\n",
    "\n",
    "![Figure 8.7](../images/figure_8_7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d975237",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- **Attention** is the phenomenon in which our minds focus on the relevant parts of the input while producing output.\n",
    "- **Attention mechanism** is the process in which sequence generation models incorporate attention to different parts of the input and not just the final summary of the input.\n",
    "- The first models to incorporate the notion of attention for NLP were machine translation models by Bahdanau(2015).\n",
    "\n",
    "![Figure 8.8](../images/figure_8_8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ec8058",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Attention in Deep Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ee4bf2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- In typical S2S Model, each time step produces a hidden state representation, denoted as $\\phi_w$, specific to that time step in the encoder.\n",
    "- To incorporate attention, we consider not only the final hidden state of the encoder but also the hidden states for each of the intermediate steps. These encoder hidden states are uninformatively called _values_.\n",
    "- Attention also depends on the previous hidden state of the decoder called the _query_. The query vector for time step $t=0$ is a fixed hyperparameter.\n",
    "- Attention is represented by a vector with the same dimension as the number of values it is attending to. This is called _attention vector_, or _attention weights_ or sometimes _alignment_.\n",
    "- The attention weights are combined with the encoder states(values) to generate a _context vector_ that sometimes also known as a _glimpse_. This context vector becomes the input for the decoder instead of the full sentence encoding.\n",
    "- The attention vector for the next time step is updated using a _compatibility function_. The exact nature of the compatibility function depends on the attention mechanism being used.\n",
    "\n",
    "![Figure 8.9](../images/figure_8_9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8be84e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Ways to Implement Attention**\n",
    "- Simplest and most common is **Content-aware Mechanism**.\n",
    "- Another popular attention is **Location-aware Attention** which depends only on query vector and the key.\n",
    "- Attention weights are typically floating-point values between 0 and 1. This is called **Soft Attention**.\n",
    "- It is also possible to learn a binary 0/1 vector for attention which is called **Hard Attention**.\n",
    "- When the encoder depends on the states for all the time step in the input, this is known as **Global Attention**.\n",
    "- In **Local Attention**, attention mechanism only depends on a window of the input around the current time step.\n",
    "- When multiple attention vector are used to track different regions of input such mechanism is known as **Multiheaded Attention** which is based on Vaswani(2017) work. This popularized the concept of **Self Attention** a mechanizm where the model learns which regions of the input influence one another.\n",
    "- When the input is multimodal like both image and speech, it is possible to design a **Multimodal Attention Mechanism**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c25495",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Evaluating Sequence Generation Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e2ab59",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Sequence Models are evaluated against an expected output called **Reference Output**.\n",
    "\n",
    "There are two kinds of evaluation for sequence generation models:\n",
    "\n",
    "- Human Evaluation\n",
    "- Automation Evaluation\n",
    "    - n-gram overlap based metrics -> BLEU, ROUGE, METEOR\n",
    "    - Perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e446e5e",
   "metadata": {},
   "source": [
    "## Example: Neural Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39e943dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\\n\\nimport os\\nfrom argparse import Namespace\\nfrom collections import Counter\\nimport json\\nimport re\\nimport string\\n\\nimport numpy as np\\nimport pandas as pd\\nimport torch\\nimport torch.nn as nn\\nfrom torch.nn import functional as F\\nimport torch.optim as optim\\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\\nfrom torch.utils.data import Dataset, DataLoader\\nfrom tqdm import notebook\\n\\nimport utils\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\n\\nimport os\\nfrom argparse import Namespace\\nfrom collections import Counter\\nimport json\\nimport re\\nimport string\\n\\nimport numpy as np\\nimport pandas as pd\\nimport torch\\nimport torch.nn as nn\\nfrom torch.nn import functional as F\\nimport torch.optim as optim\\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\\nfrom torch.utils.data import Dataset, DataLoader\\nfrom tqdm import notebook\\n\\nimport utils\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "\n",
    "import os\n",
    "from argparse import Namespace\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import notebook\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b99a47",
   "metadata": {},
   "source": [
    "### Vocabulary, Vectorizer and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7709e98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"class Vocabulary(object):\\n    def __init__(self, token_to_idx=None):\\n        if token_to_idx is None:\\n            token_to_idx = {}\\n        self._token_to_idx = token_to_idx\\n        self._idx_to_token = {idk: token for token, idx in self._token_to_idx.items()}\\n\\n    def to_serializable(self):\\n        return {\\\"token_to_idx\\\": self._token_to_idx}\\n\\n    @classmethod\\n    def from_serializable(cls, contents):\\n        return cls(**contents)\\n\\n    def add_token(self, token):\\n        if token in self._token_to_idx:\\n            index = self._token_to_idx[token]\\n        else:\\n            index = len(self._token_to_idx)\\n            self._token_to_idx[token] = index\\n            self._idx_to_token[index] = token\\n        return index\\n\\n    def add_many(self, tokens):\\n        return [self.add_token(token) for token in tokens]\\n\\n    def lookup_token(self, token):\\n        return self._token_to_idx[token]\\n\\n    def lookup_index(self, index):\\n        if index not in self._idx_to_token:\\n            raise KeyError(f\\\"The index {index} is not in the Vocab.\\\")\\n        return self._idx_to_token[index]\\n\\n    def __str__(self):\\n        return f\\\"<Vocabulary(size={len(self)})>\\\"\\n\\n    def __len__(self):\\n        return len(self._token_to_idx)\";\n",
       "                var nbb_formatted_code = \"class Vocabulary(object):\\n    def __init__(self, token_to_idx=None):\\n        if token_to_idx is None:\\n            token_to_idx = {}\\n        self._token_to_idx = token_to_idx\\n        self._idx_to_token = {idk: token for token, idx in self._token_to_idx.items()}\\n\\n    def to_serializable(self):\\n        return {\\\"token_to_idx\\\": self._token_to_idx}\\n\\n    @classmethod\\n    def from_serializable(cls, contents):\\n        return cls(**contents)\\n\\n    def add_token(self, token):\\n        if token in self._token_to_idx:\\n            index = self._token_to_idx[token]\\n        else:\\n            index = len(self._token_to_idx)\\n            self._token_to_idx[token] = index\\n            self._idx_to_token[index] = token\\n        return index\\n\\n    def add_many(self, tokens):\\n        return [self.add_token(token) for token in tokens]\\n\\n    def lookup_token(self, token):\\n        return self._token_to_idx[token]\\n\\n    def lookup_index(self, index):\\n        if index not in self._idx_to_token:\\n            raise KeyError(f\\\"The index {index} is not in the Vocab.\\\")\\n        return self._idx_to_token[index]\\n\\n    def __str__(self):\\n        return f\\\"<Vocabulary(size={len(self)})>\\\"\\n\\n    def __len__(self):\\n        return len(self._token_to_idx)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Vocabulary(object):\n",
    "    def __init__(self, token_to_idx=None):\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx\n",
    "        self._idx_to_token = {idk: token for token, idx in self._token_to_idx.items()}\n",
    "\n",
    "    def to_serializable(self):\n",
    "        return {\"token_to_idx\": self._token_to_idx}\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        return cls(**contents)\n",
    "\n",
    "    def add_token(self, token):\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "\n",
    "    def add_many(self, tokens):\n",
    "        return [self.add_token(token) for token in tokens]\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        return self._token_to_idx[token]\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(f\"The index {index} is not in the Vocab.\")\n",
    "        return self._idx_to_token[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<Vocabulary(size={len(self)})>\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "002d267a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"class SequenceVocabulary(Vocabulary):\\n    def __init__(\\n        self,\\n        token_to_idx=None,\\n        unk_token=\\\"<UNK>\\\",\\n        mask_token=\\\"<MASK>\\\",\\n        begin_seq_token=\\\"<BEGIN>\\\",\\n        end_seq_token=\\\"<END>\\\",\\n    ):\\n        super(SequenceVocabulary, self).__init__(token_to_idx)\\n        self._mask_token = mask_token\\n        self._unk_token = unk_token\\n        self._begin_seq_token = begin_seq_token\\n        self._end_seq_token = end_seq_token\\n\\n        self.mask_index = self.add_token(self._mask_token)\\n        self.unk_index = self.add_token(self._unk_token)\\n        self.begin_seq_index = self.add_token(self._begin_seq_token)\\n        self.end_seq_index = self.add_token(self._end_seq_token)\\n\\n    def to_serializable(self):\\n        contents = super(SequenceVocabulary, self).to_serializable()\\n        contents.update(\\n            {\\n                \\\"unk_token\\\": self._unk_token,\\n                \\\"mask_token\\\": self._mask_token,\\n                \\\"begin_seq_token\\\": self._begin_seq_token,\\n                \\\"end_seq_token\\\": self._end_seq_token,\\n            }\\n        )\\n        return contents\\n\\n    def lookup_token(self, token):\\n        if self.unk_index >= 0:\\n            return self._token_to_idx.get(token, self.unk_index)\\n        else:\\n            return self._token_to_idx[token]\";\n",
       "                var nbb_formatted_code = \"class SequenceVocabulary(Vocabulary):\\n    def __init__(\\n        self,\\n        token_to_idx=None,\\n        unk_token=\\\"<UNK>\\\",\\n        mask_token=\\\"<MASK>\\\",\\n        begin_seq_token=\\\"<BEGIN>\\\",\\n        end_seq_token=\\\"<END>\\\",\\n    ):\\n        super(SequenceVocabulary, self).__init__(token_to_idx)\\n        self._mask_token = mask_token\\n        self._unk_token = unk_token\\n        self._begin_seq_token = begin_seq_token\\n        self._end_seq_token = end_seq_token\\n\\n        self.mask_index = self.add_token(self._mask_token)\\n        self.unk_index = self.add_token(self._unk_token)\\n        self.begin_seq_index = self.add_token(self._begin_seq_token)\\n        self.end_seq_index = self.add_token(self._end_seq_token)\\n\\n    def to_serializable(self):\\n        contents = super(SequenceVocabulary, self).to_serializable()\\n        contents.update(\\n            {\\n                \\\"unk_token\\\": self._unk_token,\\n                \\\"mask_token\\\": self._mask_token,\\n                \\\"begin_seq_token\\\": self._begin_seq_token,\\n                \\\"end_seq_token\\\": self._end_seq_token,\\n            }\\n        )\\n        return contents\\n\\n    def lookup_token(self, token):\\n        if self.unk_index >= 0:\\n            return self._token_to_idx.get(token, self.unk_index)\\n        else:\\n            return self._token_to_idx[token]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class SequenceVocabulary(Vocabulary):\n",
    "    def __init__(\n",
    "        self,\n",
    "        token_to_idx=None,\n",
    "        unk_token=\"<UNK>\",\n",
    "        mask_token=\"<MASK>\",\n",
    "        begin_seq_token=\"<BEGIN>\",\n",
    "        end_seq_token=\"<END>\",\n",
    "    ):\n",
    "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
    "        self._mask_token = mask_token\n",
    "        self._unk_token = unk_token\n",
    "        self._begin_seq_token = begin_seq_token\n",
    "        self._end_seq_token = end_seq_token\n",
    "\n",
    "        self.mask_index = self.add_token(self._mask_token)\n",
    "        self.unk_index = self.add_token(self._unk_token)\n",
    "        self.begin_seq_index = self.add_token(self._begin_seq_token)\n",
    "        self.end_seq_index = self.add_token(self._end_seq_token)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        contents = super(SequenceVocabulary, self).to_serializable()\n",
    "        contents.update(\n",
    "            {\n",
    "                \"unk_token\": self._unk_token,\n",
    "                \"mask_token\": self._mask_token,\n",
    "                \"begin_seq_token\": self._begin_seq_token,\n",
    "                \"end_seq_token\": self._end_seq_token,\n",
    "            }\n",
    "        )\n",
    "        return contents\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb5a39c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class NMTVectorizer(object):\\n    def __init__(\\n        self, source_vocab, target_vocab, max_source_length, max_target_length\\n    ):\\n        self.source_vocab = source_vocab\\n        self.target_vocab = target_vocab\\n\\n        self.max_source_length = max_source_length\\n        self.max_target_length = max_target_length\\n\\n    def _vectorize(self, indices, vector_length=-1, mask_index=0):\\n        if vector_length < 0:\\n            vector_length = len(indices)\\n        vector = np.zeros(vector_length, dtype=np.int64)\\n        vector[: len(indices)] = indices\\n        vector[len(indices) :] = mask_index\\n        return vector\\n\\n    def _get_source_indices(self, text):\\n        indices = [self.source_vocab.begin_seq_index]\\n        indices.extend(\\n            self.source_vocab.lookup_token(token) for token in text.split(\\\" \\\")\\n        )\\n        indices.append(self.source_vocab.end_seq_index)\\n        return indices\\n\\n    def _get_target_indices(self, text):\\n        indices = [self.target_vocab.lookup_token(token) for token in text.split(\\\" \\\")]\\n        x_indices = [self.target_vocab.begin_seq_index] + indices\\n        y_indices = indices + [self.target_vocab.end_seq_index]\\n        return x_indices, y_indices\\n\\n    def vectorize(self, source_text, target_text, use_dataset_max_lengths=True):\\n        source_vector_length, target_vector_length = -1, -1\\n        if use_dataset_max_lengths:\\n            source_vector_length = self.max_source_length + 2\\n            target_vector_length = self.max_target_length + 1\\n\\n        source_indices = self._get_source_indices(source_text)\\n        source_vector = self._vectorize(\\n            source_indices,\\n            vector_length=source_vector_length,\\n            mask_index=self.source_vocab.mask_index,\\n        )\\n\\n        target_x_indices, target_y_indices = self._get_target_indices(target_text)\\n        target_x_vector = self._vectorize(\\n            target_x_indices,\\n            vector_length=target_vector_length,\\n            mask_index=self.target_vocab.mask_index,\\n        )\\n\\n        target_y_vector = self._vectorize(\\n            target_y_indices,\\n            vector_length=target_vector_length,\\n            mask_index=self.target_vocab.mask_index,\\n        )\\n        return {\\n            \\\"source_vector\\\": source_vector,\\n            \\\"target_x_vector\\\": target_x_vector,\\n            \\\"target_y_vector\\\": target_y_vector,\\n            \\\"source_length\\\": len(source_indices),\\n        }\\n\\n    @classmethod\\n    def from_dataframe(cls, bitext_df):\\n        source_vocab = SequenceVocabulary()\\n        target_vocab = SequenceVocabulary()\\n\\n        max_source_length, max_target_length = 0, 0\\n\\n        for _, row in bitext_df.iterrows():\\n            source_tokens = row[\\\"source_language\\\"].split(\\\" \\\")\\n            if len(source_tokens) > max_source_length:\\n                max_source_length = len(source_tokens)\\n            for token in source_tokens:\\n                source_vocab.add_token(token)\\n\\n            target_tokens = row[\\\"target_language\\\"].split(\\\" \\\")\\n            if len(target_tokens) > max_target_length:\\n                max_target_length = len(target_tokens)\\n            for token in target_tokens:\\n                target_vocab.add_token(token)\\n        return cls(source_vocab, target_vocab, max_source_length, max_target_length)\\n\\n    @classmethod\\n    def from_serializable(cls, contents):\\n        source_vocab = SequenceVocabulary.from_serializable(contents[\\\"source_vocab\\\"])\\n        target_vocab = SequenceVocabulary.from_serializable(contents[\\\"target_vocab\\\"])\\n        return cls(\\n            source_vocab=source_vocab,\\n            target_vocab=target_vocab,\\n            max_source_length=contents[\\\"max_source_length\\\"],\\n            max_target_length=contents[\\\"max_target_length\\\"],\\n        )\\n\\n    def to_serializable(self):\\n        return {\\n            \\\"source_vocab\\\": self.source_vocab.to_serializable(),\\n            \\\"target_vocab\\\": self.target_vocab.to_serializable(),\\n            \\\"max_source_length\\\": self.max_source_length,\\n            \\\"max_target_length\\\": self.max_target_length,\\n        }\";\n",
       "                var nbb_formatted_code = \"class NMTVectorizer(object):\\n    def __init__(\\n        self, source_vocab, target_vocab, max_source_length, max_target_length\\n    ):\\n        self.source_vocab = source_vocab\\n        self.target_vocab = target_vocab\\n\\n        self.max_source_length = max_source_length\\n        self.max_target_length = max_target_length\\n\\n    def _vectorize(self, indices, vector_length=-1, mask_index=0):\\n        if vector_length < 0:\\n            vector_length = len(indices)\\n        vector = np.zeros(vector_length, dtype=np.int64)\\n        vector[: len(indices)] = indices\\n        vector[len(indices) :] = mask_index\\n        return vector\\n\\n    def _get_source_indices(self, text):\\n        indices = [self.source_vocab.begin_seq_index]\\n        indices.extend(\\n            self.source_vocab.lookup_token(token) for token in text.split(\\\" \\\")\\n        )\\n        indices.append(self.source_vocab.end_seq_index)\\n        return indices\\n\\n    def _get_target_indices(self, text):\\n        indices = [self.target_vocab.lookup_token(token) for token in text.split(\\\" \\\")]\\n        x_indices = [self.target_vocab.begin_seq_index] + indices\\n        y_indices = indices + [self.target_vocab.end_seq_index]\\n        return x_indices, y_indices\\n\\n    def vectorize(self, source_text, target_text, use_dataset_max_lengths=True):\\n        source_vector_length, target_vector_length = -1, -1\\n        if use_dataset_max_lengths:\\n            source_vector_length = self.max_source_length + 2\\n            target_vector_length = self.max_target_length + 1\\n\\n        source_indices = self._get_source_indices(source_text)\\n        source_vector = self._vectorize(\\n            source_indices,\\n            vector_length=source_vector_length,\\n            mask_index=self.source_vocab.mask_index,\\n        )\\n\\n        target_x_indices, target_y_indices = self._get_target_indices(target_text)\\n        target_x_vector = self._vectorize(\\n            target_x_indices,\\n            vector_length=target_vector_length,\\n            mask_index=self.target_vocab.mask_index,\\n        )\\n\\n        target_y_vector = self._vectorize(\\n            target_y_indices,\\n            vector_length=target_vector_length,\\n            mask_index=self.target_vocab.mask_index,\\n        )\\n        return {\\n            \\\"source_vector\\\": source_vector,\\n            \\\"target_x_vector\\\": target_x_vector,\\n            \\\"target_y_vector\\\": target_y_vector,\\n            \\\"source_length\\\": len(source_indices),\\n        }\\n\\n    @classmethod\\n    def from_dataframe(cls, bitext_df):\\n        source_vocab = SequenceVocabulary()\\n        target_vocab = SequenceVocabulary()\\n\\n        max_source_length, max_target_length = 0, 0\\n\\n        for _, row in bitext_df.iterrows():\\n            source_tokens = row[\\\"source_language\\\"].split(\\\" \\\")\\n            if len(source_tokens) > max_source_length:\\n                max_source_length = len(source_tokens)\\n            for token in source_tokens:\\n                source_vocab.add_token(token)\\n\\n            target_tokens = row[\\\"target_language\\\"].split(\\\" \\\")\\n            if len(target_tokens) > max_target_length:\\n                max_target_length = len(target_tokens)\\n            for token in target_tokens:\\n                target_vocab.add_token(token)\\n        return cls(source_vocab, target_vocab, max_source_length, max_target_length)\\n\\n    @classmethod\\n    def from_serializable(cls, contents):\\n        source_vocab = SequenceVocabulary.from_serializable(contents[\\\"source_vocab\\\"])\\n        target_vocab = SequenceVocabulary.from_serializable(contents[\\\"target_vocab\\\"])\\n        return cls(\\n            source_vocab=source_vocab,\\n            target_vocab=target_vocab,\\n            max_source_length=contents[\\\"max_source_length\\\"],\\n            max_target_length=contents[\\\"max_target_length\\\"],\\n        )\\n\\n    def to_serializable(self):\\n        return {\\n            \\\"source_vocab\\\": self.source_vocab.to_serializable(),\\n            \\\"target_vocab\\\": self.target_vocab.to_serializable(),\\n            \\\"max_source_length\\\": self.max_source_length,\\n            \\\"max_target_length\\\": self.max_target_length,\\n        }\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NMTVectorizer(object):\n",
    "    def __init__(\n",
    "        self, source_vocab, target_vocab, max_source_length, max_target_length\n",
    "    ):\n",
    "        self.source_vocab = source_vocab\n",
    "        self.target_vocab = target_vocab\n",
    "\n",
    "        self.max_source_length = max_source_length\n",
    "        self.max_target_length = max_target_length\n",
    "\n",
    "    def _vectorize(self, indices, vector_length=-1, mask_index=0):\n",
    "        if vector_length < 0:\n",
    "            vector_length = len(indices)\n",
    "        vector = np.zeros(vector_length, dtype=np.int64)\n",
    "        vector[: len(indices)] = indices\n",
    "        vector[len(indices) :] = mask_index\n",
    "        return vector\n",
    "\n",
    "    def _get_source_indices(self, text):\n",
    "        indices = [self.source_vocab.begin_seq_index]\n",
    "        indices.extend(\n",
    "            self.source_vocab.lookup_token(token) for token in text.split(\" \")\n",
    "        )\n",
    "        indices.append(self.source_vocab.end_seq_index)\n",
    "        return indices\n",
    "\n",
    "    def _get_target_indices(self, text):\n",
    "        indices = [self.target_vocab.lookup_token(token) for token in text.split(\" \")]\n",
    "        x_indices = [self.target_vocab.begin_seq_index] + indices\n",
    "        y_indices = indices + [self.target_vocab.end_seq_index]\n",
    "        return x_indices, y_indices\n",
    "\n",
    "    def vectorize(self, source_text, target_text, use_dataset_max_lengths=True):\n",
    "        source_vector_length, target_vector_length = -1, -1\n",
    "        if use_dataset_max_lengths:\n",
    "            source_vector_length = self.max_source_length + 2\n",
    "            target_vector_length = self.max_target_length + 1\n",
    "\n",
    "        source_indices = self._get_source_indices(source_text)\n",
    "        source_vector = self._vectorize(\n",
    "            source_indices,\n",
    "            vector_length=source_vector_length,\n",
    "            mask_index=self.source_vocab.mask_index,\n",
    "        )\n",
    "\n",
    "        target_x_indices, target_y_indices = self._get_target_indices(target_text)\n",
    "        target_x_vector = self._vectorize(\n",
    "            target_x_indices,\n",
    "            vector_length=target_vector_length,\n",
    "            mask_index=self.target_vocab.mask_index,\n",
    "        )\n",
    "\n",
    "        target_y_vector = self._vectorize(\n",
    "            target_y_indices,\n",
    "            vector_length=target_vector_length,\n",
    "            mask_index=self.target_vocab.mask_index,\n",
    "        )\n",
    "        return {\n",
    "            \"source_vector\": source_vector,\n",
    "            \"target_x_vector\": target_x_vector,\n",
    "            \"target_y_vector\": target_y_vector,\n",
    "            \"source_length\": len(source_indices),\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(cls, bitext_df):\n",
    "        source_vocab = SequenceVocabulary()\n",
    "        target_vocab = SequenceVocabulary()\n",
    "\n",
    "        max_source_length, max_target_length = 0, 0\n",
    "\n",
    "        for _, row in bitext_df.iterrows():\n",
    "            source_tokens = row[\"source_language\"].split(\" \")\n",
    "            if len(source_tokens) > max_source_length:\n",
    "                max_source_length = len(source_tokens)\n",
    "            for token in source_tokens:\n",
    "                source_vocab.add_token(token)\n",
    "\n",
    "            target_tokens = row[\"target_language\"].split(\" \")\n",
    "            if len(target_tokens) > max_target_length:\n",
    "                max_target_length = len(target_tokens)\n",
    "            for token in target_tokens:\n",
    "                target_vocab.add_token(token)\n",
    "        return cls(source_vocab, target_vocab, max_source_length, max_target_length)\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        source_vocab = SequenceVocabulary.from_serializable(contents[\"source_vocab\"])\n",
    "        target_vocab = SequenceVocabulary.from_serializable(contents[\"target_vocab\"])\n",
    "        return cls(\n",
    "            source_vocab=source_vocab,\n",
    "            target_vocab=target_vocab,\n",
    "            max_source_length=contents[\"max_source_length\"],\n",
    "            max_target_length=contents[\"max_target_length\"],\n",
    "        )\n",
    "\n",
    "    def to_serializable(self):\n",
    "        return {\n",
    "            \"source_vocab\": self.source_vocab.to_serializable(),\n",
    "            \"target_vocab\": self.target_vocab.to_serializable(),\n",
    "            \"max_source_length\": self.max_source_length,\n",
    "            \"max_target_length\": self.max_target_length,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff66aaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class NMTDataset(Dataset):\\n    def __init__(self, text_df, vectorizer):\\n        self.text_df = text_df\\n        self._vectorizer = vectorizer\\n\\n        self.train_df = self.text_df[self.text_df.split == \\\"train\\\"]\\n        self.train_size = len(self.train_df)\\n\\n        self.val_df = self.text_df[self.text_df.split == \\\"val\\\"]\\n        self.val_size = len(self.val_df)\\n\\n        self.test_df = self.text_df[self.text_df.split == \\\"test\\\"]\\n        self.test_size = len(self.test_df)\\n\\n        self._lookup_dict = {\\n            \\\"train\\\": (self.train_df, self.train_size),\\n            \\\"val\\\": (self.val_df, self.val_size),\\n            \\\"test\\\": (self.test_df, self.test_size),\\n        }\\n        self.set_split(\\\"train\\\")\\n\\n    @classmethod\\n    def load_dataset_and_make_vectorizer(cls, dataset_csv):\\n        text_df = pd.read_csv(dataset_csv)\\n        train_subset = text_df[text_df.split == \\\"train\\\"]\\n        return cls(text_df, NMTVectorizer.from_dataframe(train_subset))\\n\\n    @classmethod\\n    def load_dataset_and_load_vectorizer(cls, dataset_csv, vectorizer_filepath):\\n        text_df = pd.read_csv(dataset_csv)\\n        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\\n        return cls(text_df, vectorizer)\\n\\n    @staticmethod\\n    def load_vectorizer_only(vectorizer_filepath):\\n        with open(vectorizer_filepath) as fp:\\n            return NMTVectorizer.from_serializable(json.load(fp))\\n\\n    def save_vectorizer(self, vectorizer_filepath):\\n        with open(vectorizer_filepath, \\\"w\\\") as fp:\\n            json.dump(self._vectorizer.to_serializable(), fp)\\n\\n    def get_vectorizer(self):\\n        return self._vectorizer\\n\\n    def set_split(self, split=\\\"train\\\"):\\n        self._train_split = split\\n        self._target_df, self._target_size = self._lookup_dict[split]\\n\\n    def __len__(self):\\n        return self._target_size\\n\\n    def __getitem__(self, index):\\n        row = self._target_df.iloc[index]\\n        vector_dict = self._vectorizer.vectorize(\\n            row.source_language, row.target_language\\n        )\\n        return {\\n            \\\"x_source\\\": vector_dict[\\\"source_vector\\\"],\\n            \\\"x_target\\\": vector_dict[\\\"target_x_vector\\\"],\\n            \\\"y_target\\\": vector_dict[\\\"target_y_vector\\\"],\\n            \\\"x_source_length\\\": vector_dict[\\\"source_length\\\"],\\n        }\\n\\n    def get_num_batches(self, batch_size):\\n        return len(self) // batch_size\";\n",
       "                var nbb_formatted_code = \"class NMTDataset(Dataset):\\n    def __init__(self, text_df, vectorizer):\\n        self.text_df = text_df\\n        self._vectorizer = vectorizer\\n\\n        self.train_df = self.text_df[self.text_df.split == \\\"train\\\"]\\n        self.train_size = len(self.train_df)\\n\\n        self.val_df = self.text_df[self.text_df.split == \\\"val\\\"]\\n        self.val_size = len(self.val_df)\\n\\n        self.test_df = self.text_df[self.text_df.split == \\\"test\\\"]\\n        self.test_size = len(self.test_df)\\n\\n        self._lookup_dict = {\\n            \\\"train\\\": (self.train_df, self.train_size),\\n            \\\"val\\\": (self.val_df, self.val_size),\\n            \\\"test\\\": (self.test_df, self.test_size),\\n        }\\n        self.set_split(\\\"train\\\")\\n\\n    @classmethod\\n    def load_dataset_and_make_vectorizer(cls, dataset_csv):\\n        text_df = pd.read_csv(dataset_csv)\\n        train_subset = text_df[text_df.split == \\\"train\\\"]\\n        return cls(text_df, NMTVectorizer.from_dataframe(train_subset))\\n\\n    @classmethod\\n    def load_dataset_and_load_vectorizer(cls, dataset_csv, vectorizer_filepath):\\n        text_df = pd.read_csv(dataset_csv)\\n        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\\n        return cls(text_df, vectorizer)\\n\\n    @staticmethod\\n    def load_vectorizer_only(vectorizer_filepath):\\n        with open(vectorizer_filepath) as fp:\\n            return NMTVectorizer.from_serializable(json.load(fp))\\n\\n    def save_vectorizer(self, vectorizer_filepath):\\n        with open(vectorizer_filepath, \\\"w\\\") as fp:\\n            json.dump(self._vectorizer.to_serializable(), fp)\\n\\n    def get_vectorizer(self):\\n        return self._vectorizer\\n\\n    def set_split(self, split=\\\"train\\\"):\\n        self._train_split = split\\n        self._target_df, self._target_size = self._lookup_dict[split]\\n\\n    def __len__(self):\\n        return self._target_size\\n\\n    def __getitem__(self, index):\\n        row = self._target_df.iloc[index]\\n        vector_dict = self._vectorizer.vectorize(\\n            row.source_language, row.target_language\\n        )\\n        return {\\n            \\\"x_source\\\": vector_dict[\\\"source_vector\\\"],\\n            \\\"x_target\\\": vector_dict[\\\"target_x_vector\\\"],\\n            \\\"y_target\\\": vector_dict[\\\"target_y_vector\\\"],\\n            \\\"x_source_length\\\": vector_dict[\\\"source_length\\\"],\\n        }\\n\\n    def get_num_batches(self, batch_size):\\n        return len(self) // batch_size\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, text_df, vectorizer):\n",
    "        self.text_df = text_df\n",
    "        self._vectorizer = vectorizer\n",
    "\n",
    "        self.train_df = self.text_df[self.text_df.split == \"train\"]\n",
    "        self.train_size = len(self.train_df)\n",
    "\n",
    "        self.val_df = self.text_df[self.text_df.split == \"val\"]\n",
    "        self.val_size = len(self.val_df)\n",
    "\n",
    "        self.test_df = self.text_df[self.text_df.split == \"test\"]\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        self._lookup_dict = {\n",
    "            \"train\": (self.train_df, self.train_size),\n",
    "            \"val\": (self.val_df, self.val_size),\n",
    "            \"test\": (self.test_df, self.test_size),\n",
    "        }\n",
    "        self.set_split(\"train\")\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, dataset_csv):\n",
    "        text_df = pd.read_csv(dataset_csv)\n",
    "        train_subset = text_df[text_df.split == \"train\"]\n",
    "        return cls(text_df, NMTVectorizer.from_dataframe(train_subset))\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_load_vectorizer(cls, dataset_csv, vectorizer_filepath):\n",
    "        text_df = pd.read_csv(dataset_csv)\n",
    "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
    "        return cls(text_df, vectorizer)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vectorizer_only(vectorizer_filepath):\n",
    "        with open(vectorizer_filepath) as fp:\n",
    "            return NMTVectorizer.from_serializable(json.load(fp))\n",
    "\n",
    "    def save_vectorizer(self, vectorizer_filepath):\n",
    "        with open(vectorizer_filepath, \"w\") as fp:\n",
    "            json.dump(self._vectorizer.to_serializable(), fp)\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "        return self._vectorizer\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        self._train_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self._target_df.iloc[index]\n",
    "        vector_dict = self._vectorizer.vectorize(\n",
    "            row.source_language, row.target_language\n",
    "        )\n",
    "        return {\n",
    "            \"x_source\": vector_dict[\"source_vector\"],\n",
    "            \"x_target\": vector_dict[\"target_x_vector\"],\n",
    "            \"y_target\": vector_dict[\"target_y_vector\"],\n",
    "            \"x_source_length\": vector_dict[\"source_length\"],\n",
    "        }\n",
    "\n",
    "    def get_num_batches(self, batch_size):\n",
    "        return len(self) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7798d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"def generate_nmt_batches(\\n    dataset, batch_size, shuffle=True, drop_last=True, device=\\\"cpu\\\"\\n):\\n    dataloader = DataLoader(\\n        dataset=dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last\\n    )\\n    for data_dict in dataloader:\\n        lengths = data_dict[\\\"x_source_length\\\"].numpy()\\n        sorted_length_indices = lengths.argsort()[::-1].tolist()\\n\\n        out_data_dict = {}\\n        for name, tensor in data_dict.items():\\n            out_data_dict[name] = data_dict[name][sorted_length_indices].to(device)\\n        yield out_data_dict\";\n",
       "                var nbb_formatted_code = \"def generate_nmt_batches(\\n    dataset, batch_size, shuffle=True, drop_last=True, device=\\\"cpu\\\"\\n):\\n    dataloader = DataLoader(\\n        dataset=dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last\\n    )\\n    for data_dict in dataloader:\\n        lengths = data_dict[\\\"x_source_length\\\"].numpy()\\n        sorted_length_indices = lengths.argsort()[::-1].tolist()\\n\\n        out_data_dict = {}\\n        for name, tensor in data_dict.items():\\n            out_data_dict[name] = data_dict[name][sorted_length_indices].to(device)\\n        yield out_data_dict\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_nmt_batches(\n",
    "    dataset, batch_size, shuffle=True, drop_last=True, device=\"cpu\"\n",
    "):\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last\n",
    "    )\n",
    "    for data_dict in dataloader:\n",
    "        lengths = data_dict[\"x_source_length\"].numpy()\n",
    "        sorted_length_indices = lengths.argsort()[::-1].tolist()\n",
    "\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name][sorted_length_indices].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59580f79",
   "metadata": {},
   "source": [
    "### NMT Model with No Sampling\n",
    "\n",
    "Components:\n",
    "\n",
    "1. NMTEncoder\n",
    "    - accepts as input a source sequence to be embedded and fed through a bi-directional GRU\n",
    "2. NMTDecoder\n",
    "    - using the encoder state and attention, the decoder generates a new sequence\n",
    "    - the ground truth target sequence is used as input to the decoder at each time step\n",
    "    - an alternative formulation would allow some of the decoder's own choices to be used as input\n",
    "    - this is referred to as curriculum learning, learning to search\n",
    "        - TODO: Look up references for this. I believe Bengio has a paper from the image captioning competitions. Hal Daume has tons on this and is the main NLP guy for it.\n",
    "3. NMTModel\n",
    "    - Combines the encoder and decoder into a single class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9fb4230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"def verbose_attention(encoder_state_vectors, query_vector):\\n    batch_size, num_vectors, vector_size = encoder_state_vectors.size()\\n    vector_scores = torch.sum(\\n        encoder_state_vectors * query_vector.view(batch_size, 1, vector_size), dim=2\\n    )\\n    vector_probabilities = F.softmax(vector_scores, dim=1)\\n    weighted_vectors = encoder_state_vectors * vector_probabilities.view(\\n        batch_size, num_vectors, 1\\n    )\\n    context_vectors = torch.sum(weighted_vectors, dim=1)\\n    return context_vectors, vector_probabilities, vector_scores\\n\\n\\ndef terse_attention(encoder_state_vectors, query_vector):\\n    vector_scores = torch.matmul(\\n        encoder_state_vectors, query_vector.unsqueeze(dim=2)\\n    ).squeeze()\\n    vector_probabilities = F.softmax(vector_scores, dim=-1)\\n    context_vectors = torch.matmul(\\n        encoder_state_vectors.transpose(-2, -1), vector_probabilities.unsqueeze(dim=2)\\n    ).squeeze()\\n    return context_vectors, vector_probabilities\";\n",
       "                var nbb_formatted_code = \"def verbose_attention(encoder_state_vectors, query_vector):\\n    batch_size, num_vectors, vector_size = encoder_state_vectors.size()\\n    vector_scores = torch.sum(\\n        encoder_state_vectors * query_vector.view(batch_size, 1, vector_size), dim=2\\n    )\\n    vector_probabilities = F.softmax(vector_scores, dim=1)\\n    weighted_vectors = encoder_state_vectors * vector_probabilities.view(\\n        batch_size, num_vectors, 1\\n    )\\n    context_vectors = torch.sum(weighted_vectors, dim=1)\\n    return context_vectors, vector_probabilities, vector_scores\\n\\n\\ndef terse_attention(encoder_state_vectors, query_vector):\\n    vector_scores = torch.matmul(\\n        encoder_state_vectors, query_vector.unsqueeze(dim=2)\\n    ).squeeze()\\n    vector_probabilities = F.softmax(vector_scores, dim=-1)\\n    context_vectors = torch.matmul(\\n        encoder_state_vectors.transpose(-2, -1), vector_probabilities.unsqueeze(dim=2)\\n    ).squeeze()\\n    return context_vectors, vector_probabilities\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def verbose_attention(encoder_state_vectors, query_vector):\n",
    "    batch_size, num_vectors, vector_size = encoder_state_vectors.size()\n",
    "    vector_scores = torch.sum(\n",
    "        encoder_state_vectors * query_vector.view(batch_size, 1, vector_size), dim=2\n",
    "    )\n",
    "    vector_probabilities = F.softmax(vector_scores, dim=1)\n",
    "    weighted_vectors = encoder_state_vectors * vector_probabilities.view(\n",
    "        batch_size, num_vectors, 1\n",
    "    )\n",
    "    context_vectors = torch.sum(weighted_vectors, dim=1)\n",
    "    return context_vectors, vector_probabilities, vector_scores\n",
    "\n",
    "\n",
    "def terse_attention(encoder_state_vectors, query_vector):\n",
    "    vector_scores = torch.matmul(\n",
    "        encoder_state_vectors, query_vector.unsqueeze(dim=2)\n",
    "    ).squeeze()\n",
    "    vector_probabilities = F.softmax(vector_scores, dim=-1)\n",
    "    context_vectors = torch.matmul(\n",
    "        encoder_state_vectors.transpose(-2, -1), vector_probabilities.unsqueeze(dim=2)\n",
    "    ).squeeze()\n",
    "    return context_vectors, vector_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "206a7669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class NMTEncoder(nn.Module):\\n    def __init__(self, num_embeddings, embedding_size, rnn_hidden_size):\\n        \\\"\\\"\\\"\\n        Args:\\n            num_embeddings (int): number of embeddings is the size of source vocabulary\\n            embedding_size (int): size of the embedding vectors\\n            rnn_hidden_size (int): size of the RNN hidden state vectors\\n        \\\"\\\"\\\"\\n        super(NMTEncoder, self).__init__()\\n\\n        self.source_embedding = nn.Embedding(\\n            num_embeddings, embedding_size, padding_idx=0\\n        )\\n        self.birnn = nn.GRU(\\n            embedding_size, rnn_hidden_size, bidirectional=True, batch_first=True\\n        )\\n\\n    def forward(self, x_source, x_lengths):\\n        \\\"\\\"\\\"The forward pass of the model\\n\\n        Args:\\n            x_source (torch.Tensor): the input data tensor.\\n                x_source.shape is (batch, seq_size)\\n            x_lengths (torch.Tensor): a vector of lengths for each item in the batch\\n        Returns:\\n            a tuple: x_unpacked (torch.Tensor), x_birnn_h (torch.Tensor)\\n                x_unpacked.shape = (batch, seq_size, rnn_hidden_size * 2)\\n                x_birnn_h.shape = (batch, rnn_hidden_size * 2)\\n        \\\"\\\"\\\"\\n        x_embedded = self.source_embedding(x_source)\\n        # create PackedSequence; x_packed.data.shape=(number_items, embeddign_size)\\n        x_packed = pack_padded_sequence(\\n            x_embedded,\\n            x_lengths.detach().cpu().numpy(),\\n            batch_first=True,\\n            enforce_sorted=False,\\n        )\\n\\n        # x_birnn_h.shape = (num_rnn, batch_size, feature_size)\\n        x_birnn_out, x_birnn_h = self.birnn(x_packed)\\n        # permute to (batch_size, num_rnn, feature_size)\\n        x_birnn_h = x_birnn_h.permute(1, 0, 2)\\n\\n        # flatten features; reshape to (batch_size, num_rnn * feature_size)\\n        #  (recall: -1 takes the remaining positions,\\n        #           flattening the two RNN hidden vectors into 1)\\n        x_birnn_h = x_birnn_h.contiguous().view(x_birnn_h.size(0), -1)\\n\\n        x_unpacked, _ = pad_packed_sequence(x_birnn_out, batch_first=True)\\n\\n        return x_unpacked, x_birnn_h\";\n",
       "                var nbb_formatted_code = \"class NMTEncoder(nn.Module):\\n    def __init__(self, num_embeddings, embedding_size, rnn_hidden_size):\\n        \\\"\\\"\\\"\\n        Args:\\n            num_embeddings (int): number of embeddings is the size of source vocabulary\\n            embedding_size (int): size of the embedding vectors\\n            rnn_hidden_size (int): size of the RNN hidden state vectors\\n        \\\"\\\"\\\"\\n        super(NMTEncoder, self).__init__()\\n\\n        self.source_embedding = nn.Embedding(\\n            num_embeddings, embedding_size, padding_idx=0\\n        )\\n        self.birnn = nn.GRU(\\n            embedding_size, rnn_hidden_size, bidirectional=True, batch_first=True\\n        )\\n\\n    def forward(self, x_source, x_lengths):\\n        \\\"\\\"\\\"The forward pass of the model\\n\\n        Args:\\n            x_source (torch.Tensor): the input data tensor.\\n                x_source.shape is (batch, seq_size)\\n            x_lengths (torch.Tensor): a vector of lengths for each item in the batch\\n        Returns:\\n            a tuple: x_unpacked (torch.Tensor), x_birnn_h (torch.Tensor)\\n                x_unpacked.shape = (batch, seq_size, rnn_hidden_size * 2)\\n                x_birnn_h.shape = (batch, rnn_hidden_size * 2)\\n        \\\"\\\"\\\"\\n        x_embedded = self.source_embedding(x_source)\\n        # create PackedSequence; x_packed.data.shape=(number_items, embeddign_size)\\n        x_packed = pack_padded_sequence(\\n            x_embedded,\\n            x_lengths.detach().cpu().numpy(),\\n            batch_first=True,\\n            enforce_sorted=False,\\n        )\\n\\n        # x_birnn_h.shape = (num_rnn, batch_size, feature_size)\\n        x_birnn_out, x_birnn_h = self.birnn(x_packed)\\n        # permute to (batch_size, num_rnn, feature_size)\\n        x_birnn_h = x_birnn_h.permute(1, 0, 2)\\n\\n        # flatten features; reshape to (batch_size, num_rnn * feature_size)\\n        #  (recall: -1 takes the remaining positions,\\n        #           flattening the two RNN hidden vectors into 1)\\n        x_birnn_h = x_birnn_h.contiguous().view(x_birnn_h.size(0), -1)\\n\\n        x_unpacked, _ = pad_packed_sequence(x_birnn_out, batch_first=True)\\n\\n        return x_unpacked, x_birnn_h\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NMTEncoder(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_size, rnn_hidden_size):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_embeddings (int): number of embeddings is the size of source vocabulary\n",
    "            embedding_size (int): size of the embedding vectors\n",
    "            rnn_hidden_size (int): size of the RNN hidden state vectors\n",
    "        \"\"\"\n",
    "        super(NMTEncoder, self).__init__()\n",
    "\n",
    "        self.source_embedding = nn.Embedding(\n",
    "            num_embeddings, embedding_size, padding_idx=0\n",
    "        )\n",
    "        self.birnn = nn.GRU(\n",
    "            embedding_size, rnn_hidden_size, bidirectional=True, batch_first=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x_source, x_lengths):\n",
    "        \"\"\"The forward pass of the model\n",
    "\n",
    "        Args:\n",
    "            x_source (torch.Tensor): the input data tensor.\n",
    "                x_source.shape is (batch, seq_size)\n",
    "            x_lengths (torch.Tensor): a vector of lengths for each item in the batch\n",
    "        Returns:\n",
    "            a tuple: x_unpacked (torch.Tensor), x_birnn_h (torch.Tensor)\n",
    "                x_unpacked.shape = (batch, seq_size, rnn_hidden_size * 2)\n",
    "                x_birnn_h.shape = (batch, rnn_hidden_size * 2)\n",
    "        \"\"\"\n",
    "        x_embedded = self.source_embedding(x_source)\n",
    "        # create PackedSequence; x_packed.data.shape=(number_items, embeddign_size)\n",
    "        x_packed = pack_padded_sequence(\n",
    "            x_embedded,\n",
    "            x_lengths.detach().cpu().numpy(),\n",
    "            batch_first=True,\n",
    "            enforce_sorted=False,\n",
    "        )\n",
    "\n",
    "        # x_birnn_h.shape = (num_rnn, batch_size, feature_size)\n",
    "        x_birnn_out, x_birnn_h = self.birnn(x_packed)\n",
    "        # permute to (batch_size, num_rnn, feature_size)\n",
    "        x_birnn_h = x_birnn_h.permute(1, 0, 2)\n",
    "\n",
    "        # flatten features; reshape to (batch_size, num_rnn * feature_size)\n",
    "        #  (recall: -1 takes the remaining positions,\n",
    "        #           flattening the two RNN hidden vectors into 1)\n",
    "        x_birnn_h = x_birnn_h.contiguous().view(x_birnn_h.size(0), -1)\n",
    "\n",
    "        x_unpacked, _ = pad_packed_sequence(x_birnn_out, batch_first=True)\n",
    "\n",
    "        return x_unpacked, x_birnn_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95920076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class NMTDecoder(nn.Module):\\n    def __init__(self, num_embeddings, embedding_size, rnn_hidden_size, bos_index):\\n        \\\"\\\"\\\"\\n        Args:\\n            num_embeddings (int): number of embeddings is also the number of\\n                unique words in target vocabulary\\n            embedding_size (int): the embedding vector size\\n            rnn_hidden_size (int): size of the hidden rnn state\\n            bos_index(int): begin-of-sequence index\\n        \\\"\\\"\\\"\\n        super(NMTDecoder, self).__init__()\\n        self._rnn_hidden_size = rnn_hidden_size\\n        self.target_embedding = nn.Embedding(\\n            num_embeddings=num_embeddings, embedding_dim=embedding_size, padding_idx=0\\n        )\\n        self.gru_cell = nn.GRUCell(embedding_size + rnn_hidden_size, rnn_hidden_size)\\n        self.hidden_map = nn.Linear(rnn_hidden_size, rnn_hidden_size)\\n        self.classifier = nn.Linear(rnn_hidden_size * 2, num_embeddings)\\n        self.bos_index = bos_index\\n\\n    def _init_indices(self, batch_size):\\n        \\\"\\\"\\\"return the BEGIN-OF-SEQUENCE index vector\\\"\\\"\\\"\\n        return torch.ones(batch_size, dtype=torch.int64) * self.bos_index\\n\\n    def _init_context_vectors(self, batch_size):\\n        \\\"\\\"\\\"return a zeros vector for initializing the context\\\"\\\"\\\"\\n        return torch.zeros(batch_size, self._rnn_hidden_size)\\n\\n    def forward(self, encoder_state, initial_hidden_state, target_sequence):\\n        \\\"\\\"\\\"The forward pass of the model\\n\\n        Args:\\n            encoder_state (torch.Tensor): the output of the NMTEncoder\\n            initial_hidden_state (torch.Tensor): The last hidden state in the  NMTEncoder\\n            target_sequence (torch.Tensor): the target text data tensor\\n        Returns:\\n            output_vectors (torch.Tensor): prediction vectors at each output step\\n        \\\"\\\"\\\"\\n        # We are making an assumption there: The batch is on first\\n        # The input is (Batch, Seq)\\n        # We want to iterate over sequence so we permute it to (S, B)\\n        target_sequence = target_sequence.permute(1, 0)\\n        output_sequence_size = target_sequence.size(0)\\n\\n        # use the provided encoder hidden state as the initial hidden state\\n        h_t = self.hidden_map(initial_hidden_state)\\n\\n        batch_size = encoder_state.size(0)\\n        # initialize context vectors to zeros\\n        context_vectors = self._init_context_vectors(batch_size)\\n        # initialize first y_t word as BOS\\n        y_t_index = self._init_indices(batch_size)\\n\\n        h_t = h_t.to(encoder_state.device)\\n        y_t_index = y_t_index.to(encoder_state.device)\\n        context_vectors = context_vectors.to(encoder_state.device)\\n\\n        output_vectors = []\\n        self._cached_p_attn = []\\n        self._cached_ht = []\\n        self._cached_decoder_state = encoder_state.cpu().detach().numpy()\\n\\n        for i in range(output_sequence_size):\\n            y_t_index = target_sequence[i]\\n\\n            # Step 1: Embed word and concat with previous context\\n            y_input_vector = self.target_embedding(y_t_index)\\n            rnn_input = torch.cat([y_input_vector, context_vectors], dim=1)\\n\\n            # Step 2: Make a GRU step, getting a new hidden vector\\n            h_t = self.gru_cell(rnn_input, h_t)\\n            self._cached_ht.append(h_t.cpu().detach().numpy())\\n\\n            # Step 3: Use the current hidden to attend to the encoder state\\n            context_vectors, p_attn, _ = verbose_attention(\\n                encoder_state_vectors=encoder_state, query_vector=h_t\\n            )\\n\\n            # auxillary: cache the attention probabilities for visualization\\n            self._cached_p_attn.append(p_attn.cpu().detach().numpy())\\n\\n            # Step 4: Use the current hidden and context vectors to make a prediction to the next word\\n            prediction_vector = torch.cat((context_vectors, h_t), dim=1)\\n            score_for_y_t_index = self.classifier(F.dropout(prediction_vector, 0.3))\\n\\n            # auxillary: collect the prediction scores\\n            output_vectors.append(score_for_y_t_index)\\n\\n        output_vectors = torch.stack(output_vectors).permute(1, 0, 2)\\n\\n        return output_vectors\";\n",
       "                var nbb_formatted_code = \"class NMTDecoder(nn.Module):\\n    def __init__(self, num_embeddings, embedding_size, rnn_hidden_size, bos_index):\\n        \\\"\\\"\\\"\\n        Args:\\n            num_embeddings (int): number of embeddings is also the number of\\n                unique words in target vocabulary\\n            embedding_size (int): the embedding vector size\\n            rnn_hidden_size (int): size of the hidden rnn state\\n            bos_index(int): begin-of-sequence index\\n        \\\"\\\"\\\"\\n        super(NMTDecoder, self).__init__()\\n        self._rnn_hidden_size = rnn_hidden_size\\n        self.target_embedding = nn.Embedding(\\n            num_embeddings=num_embeddings, embedding_dim=embedding_size, padding_idx=0\\n        )\\n        self.gru_cell = nn.GRUCell(embedding_size + rnn_hidden_size, rnn_hidden_size)\\n        self.hidden_map = nn.Linear(rnn_hidden_size, rnn_hidden_size)\\n        self.classifier = nn.Linear(rnn_hidden_size * 2, num_embeddings)\\n        self.bos_index = bos_index\\n\\n    def _init_indices(self, batch_size):\\n        \\\"\\\"\\\"return the BEGIN-OF-SEQUENCE index vector\\\"\\\"\\\"\\n        return torch.ones(batch_size, dtype=torch.int64) * self.bos_index\\n\\n    def _init_context_vectors(self, batch_size):\\n        \\\"\\\"\\\"return a zeros vector for initializing the context\\\"\\\"\\\"\\n        return torch.zeros(batch_size, self._rnn_hidden_size)\\n\\n    def forward(self, encoder_state, initial_hidden_state, target_sequence):\\n        \\\"\\\"\\\"The forward pass of the model\\n\\n        Args:\\n            encoder_state (torch.Tensor): the output of the NMTEncoder\\n            initial_hidden_state (torch.Tensor): The last hidden state in the  NMTEncoder\\n            target_sequence (torch.Tensor): the target text data tensor\\n        Returns:\\n            output_vectors (torch.Tensor): prediction vectors at each output step\\n        \\\"\\\"\\\"\\n        # We are making an assumption there: The batch is on first\\n        # The input is (Batch, Seq)\\n        # We want to iterate over sequence so we permute it to (S, B)\\n        target_sequence = target_sequence.permute(1, 0)\\n        output_sequence_size = target_sequence.size(0)\\n\\n        # use the provided encoder hidden state as the initial hidden state\\n        h_t = self.hidden_map(initial_hidden_state)\\n\\n        batch_size = encoder_state.size(0)\\n        # initialize context vectors to zeros\\n        context_vectors = self._init_context_vectors(batch_size)\\n        # initialize first y_t word as BOS\\n        y_t_index = self._init_indices(batch_size)\\n\\n        h_t = h_t.to(encoder_state.device)\\n        y_t_index = y_t_index.to(encoder_state.device)\\n        context_vectors = context_vectors.to(encoder_state.device)\\n\\n        output_vectors = []\\n        self._cached_p_attn = []\\n        self._cached_ht = []\\n        self._cached_decoder_state = encoder_state.cpu().detach().numpy()\\n\\n        for i in range(output_sequence_size):\\n            y_t_index = target_sequence[i]\\n\\n            # Step 1: Embed word and concat with previous context\\n            y_input_vector = self.target_embedding(y_t_index)\\n            rnn_input = torch.cat([y_input_vector, context_vectors], dim=1)\\n\\n            # Step 2: Make a GRU step, getting a new hidden vector\\n            h_t = self.gru_cell(rnn_input, h_t)\\n            self._cached_ht.append(h_t.cpu().detach().numpy())\\n\\n            # Step 3: Use the current hidden to attend to the encoder state\\n            context_vectors, p_attn, _ = verbose_attention(\\n                encoder_state_vectors=encoder_state, query_vector=h_t\\n            )\\n\\n            # auxillary: cache the attention probabilities for visualization\\n            self._cached_p_attn.append(p_attn.cpu().detach().numpy())\\n\\n            # Step 4: Use the current hidden and context vectors to make a prediction to the next word\\n            prediction_vector = torch.cat((context_vectors, h_t), dim=1)\\n            score_for_y_t_index = self.classifier(F.dropout(prediction_vector, 0.3))\\n\\n            # auxillary: collect the prediction scores\\n            output_vectors.append(score_for_y_t_index)\\n\\n        output_vectors = torch.stack(output_vectors).permute(1, 0, 2)\\n\\n        return output_vectors\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NMTDecoder(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_size, rnn_hidden_size, bos_index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_embeddings (int): number of embeddings is also the number of\n",
    "                unique words in target vocabulary\n",
    "            embedding_size (int): the embedding vector size\n",
    "            rnn_hidden_size (int): size of the hidden rnn state\n",
    "            bos_index(int): begin-of-sequence index\n",
    "        \"\"\"\n",
    "        super(NMTDecoder, self).__init__()\n",
    "        self._rnn_hidden_size = rnn_hidden_size\n",
    "        self.target_embedding = nn.Embedding(\n",
    "            num_embeddings=num_embeddings, embedding_dim=embedding_size, padding_idx=0\n",
    "        )\n",
    "        self.gru_cell = nn.GRUCell(embedding_size + rnn_hidden_size, rnn_hidden_size)\n",
    "        self.hidden_map = nn.Linear(rnn_hidden_size, rnn_hidden_size)\n",
    "        self.classifier = nn.Linear(rnn_hidden_size * 2, num_embeddings)\n",
    "        self.bos_index = bos_index\n",
    "\n",
    "    def _init_indices(self, batch_size):\n",
    "        \"\"\"return the BEGIN-OF-SEQUENCE index vector\"\"\"\n",
    "        return torch.ones(batch_size, dtype=torch.int64) * self.bos_index\n",
    "\n",
    "    def _init_context_vectors(self, batch_size):\n",
    "        \"\"\"return a zeros vector for initializing the context\"\"\"\n",
    "        return torch.zeros(batch_size, self._rnn_hidden_size)\n",
    "\n",
    "    def forward(self, encoder_state, initial_hidden_state, target_sequence):\n",
    "        \"\"\"The forward pass of the model\n",
    "\n",
    "        Args:\n",
    "            encoder_state (torch.Tensor): the output of the NMTEncoder\n",
    "            initial_hidden_state (torch.Tensor): The last hidden state in the  NMTEncoder\n",
    "            target_sequence (torch.Tensor): the target text data tensor\n",
    "        Returns:\n",
    "            output_vectors (torch.Tensor): prediction vectors at each output step\n",
    "        \"\"\"\n",
    "        # We are making an assumption there: The batch is on first\n",
    "        # The input is (Batch, Seq)\n",
    "        # We want to iterate over sequence so we permute it to (S, B)\n",
    "        target_sequence = target_sequence.permute(1, 0)\n",
    "        output_sequence_size = target_sequence.size(0)\n",
    "\n",
    "        # use the provided encoder hidden state as the initial hidden state\n",
    "        h_t = self.hidden_map(initial_hidden_state)\n",
    "\n",
    "        batch_size = encoder_state.size(0)\n",
    "        # initialize context vectors to zeros\n",
    "        context_vectors = self._init_context_vectors(batch_size)\n",
    "        # initialize first y_t word as BOS\n",
    "        y_t_index = self._init_indices(batch_size)\n",
    "\n",
    "        h_t = h_t.to(encoder_state.device)\n",
    "        y_t_index = y_t_index.to(encoder_state.device)\n",
    "        context_vectors = context_vectors.to(encoder_state.device)\n",
    "\n",
    "        output_vectors = []\n",
    "        self._cached_p_attn = []\n",
    "        self._cached_ht = []\n",
    "        self._cached_decoder_state = encoder_state.cpu().detach().numpy()\n",
    "\n",
    "        for i in range(output_sequence_size):\n",
    "            y_t_index = target_sequence[i]\n",
    "\n",
    "            # Step 1: Embed word and concat with previous context\n",
    "            y_input_vector = self.target_embedding(y_t_index)\n",
    "            rnn_input = torch.cat([y_input_vector, context_vectors], dim=1)\n",
    "\n",
    "            # Step 2: Make a GRU step, getting a new hidden vector\n",
    "            h_t = self.gru_cell(rnn_input, h_t)\n",
    "            self._cached_ht.append(h_t.cpu().detach().numpy())\n",
    "\n",
    "            # Step 3: Use the current hidden to attend to the encoder state\n",
    "            context_vectors, p_attn, _ = verbose_attention(\n",
    "                encoder_state_vectors=encoder_state, query_vector=h_t\n",
    "            )\n",
    "\n",
    "            # auxillary: cache the attention probabilities for visualization\n",
    "            self._cached_p_attn.append(p_attn.cpu().detach().numpy())\n",
    "\n",
    "            # Step 4: Use the current hidden and context vectors to make a prediction to the next word\n",
    "            prediction_vector = torch.cat((context_vectors, h_t), dim=1)\n",
    "            score_for_y_t_index = self.classifier(F.dropout(prediction_vector, 0.3))\n",
    "\n",
    "            # auxillary: collect the prediction scores\n",
    "            output_vectors.append(score_for_y_t_index)\n",
    "\n",
    "        output_vectors = torch.stack(output_vectors).permute(1, 0, 2)\n",
    "\n",
    "        return output_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0ac9d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class NMTModel(nn.Module):\\n    \\\"\\\"\\\"The Neural Machine Translation Model\\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        source_vocab_size,\\n        source_embedding_size,\\n        target_vocab_size,\\n        target_embedding_size,\\n        encoding_size,\\n        target_bos_index,\\n    ):\\n        \\\"\\\"\\\"\\n        Args:\\n            source_vocab_size (int): number of unique words in source language\\n            source_embedding_size (int): size of the source embedding vectors\\n            target_vocab_size (int): number of unique words in target language\\n            target_embedding_size (int): size of the target embedding vectors\\n            encoding_size (int): the size of the encoder RNN.\\n        \\\"\\\"\\\"\\n        super(NMTModel, self).__init__()\\n        self.encoder = NMTEncoder(\\n            num_embeddings=source_vocab_size,\\n            embedding_size=source_embedding_size,\\n            rnn_hidden_size=encoding_size,\\n        )\\n        decoding_size = encoding_size * 2\\n        self.decoder = NMTDecoder(\\n            num_embeddings=target_vocab_size,\\n            embedding_size=target_embedding_size,\\n            rnn_hidden_size=decoding_size,\\n            bos_index=target_bos_index,\\n        )\\n\\n    def forward(self, x_source, x_source_lengths, target_sequence):\\n        \\\"\\\"\\\"The forward pass of the model\\n\\n        Args:\\n            x_source (torch.Tensor): the source text data tensor.\\n                x_source.shape should be (batch, vectorizer.max_source_length)\\n            x_source_lengths torch.Tensor): the length of the sequences in x_source\\n            target_sequence (torch.Tensor): the target text data tensor\\n        Returns:\\n            decoded_states (torch.Tensor): prediction vectors at each output step\\n        \\\"\\\"\\\"\\n        encoder_state, final_hidden_states = self.encoder(x_source, x_source_lengths)\\n        decoded_states = self.decoder(\\n            encoder_state=encoder_state,\\n            initial_hidden_state=final_hidden_states,\\n            target_sequence=target_sequence,\\n        )\\n        return decoded_states\";\n",
       "                var nbb_formatted_code = \"class NMTModel(nn.Module):\\n    \\\"\\\"\\\"The Neural Machine Translation Model\\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        source_vocab_size,\\n        source_embedding_size,\\n        target_vocab_size,\\n        target_embedding_size,\\n        encoding_size,\\n        target_bos_index,\\n    ):\\n        \\\"\\\"\\\"\\n        Args:\\n            source_vocab_size (int): number of unique words in source language\\n            source_embedding_size (int): size of the source embedding vectors\\n            target_vocab_size (int): number of unique words in target language\\n            target_embedding_size (int): size of the target embedding vectors\\n            encoding_size (int): the size of the encoder RNN.\\n        \\\"\\\"\\\"\\n        super(NMTModel, self).__init__()\\n        self.encoder = NMTEncoder(\\n            num_embeddings=source_vocab_size,\\n            embedding_size=source_embedding_size,\\n            rnn_hidden_size=encoding_size,\\n        )\\n        decoding_size = encoding_size * 2\\n        self.decoder = NMTDecoder(\\n            num_embeddings=target_vocab_size,\\n            embedding_size=target_embedding_size,\\n            rnn_hidden_size=decoding_size,\\n            bos_index=target_bos_index,\\n        )\\n\\n    def forward(self, x_source, x_source_lengths, target_sequence):\\n        \\\"\\\"\\\"The forward pass of the model\\n\\n        Args:\\n            x_source (torch.Tensor): the source text data tensor.\\n                x_source.shape should be (batch, vectorizer.max_source_length)\\n            x_source_lengths torch.Tensor): the length of the sequences in x_source\\n            target_sequence (torch.Tensor): the target text data tensor\\n        Returns:\\n            decoded_states (torch.Tensor): prediction vectors at each output step\\n        \\\"\\\"\\\"\\n        encoder_state, final_hidden_states = self.encoder(x_source, x_source_lengths)\\n        decoded_states = self.decoder(\\n            encoder_state=encoder_state,\\n            initial_hidden_state=final_hidden_states,\\n            target_sequence=target_sequence,\\n        )\\n        return decoded_states\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NMTModel(nn.Module):\n",
    "    \"\"\"The Neural Machine Translation Model\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        source_vocab_size,\n",
    "        source_embedding_size,\n",
    "        target_vocab_size,\n",
    "        target_embedding_size,\n",
    "        encoding_size,\n",
    "        target_bos_index,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            source_vocab_size (int): number of unique words in source language\n",
    "            source_embedding_size (int): size of the source embedding vectors\n",
    "            target_vocab_size (int): number of unique words in target language\n",
    "            target_embedding_size (int): size of the target embedding vectors\n",
    "            encoding_size (int): the size of the encoder RNN.\n",
    "        \"\"\"\n",
    "        super(NMTModel, self).__init__()\n",
    "        self.encoder = NMTEncoder(\n",
    "            num_embeddings=source_vocab_size,\n",
    "            embedding_size=source_embedding_size,\n",
    "            rnn_hidden_size=encoding_size,\n",
    "        )\n",
    "        decoding_size = encoding_size * 2\n",
    "        self.decoder = NMTDecoder(\n",
    "            num_embeddings=target_vocab_size,\n",
    "            embedding_size=target_embedding_size,\n",
    "            rnn_hidden_size=decoding_size,\n",
    "            bos_index=target_bos_index,\n",
    "        )\n",
    "\n",
    "    def forward(self, x_source, x_source_lengths, target_sequence):\n",
    "        \"\"\"The forward pass of the model\n",
    "\n",
    "        Args:\n",
    "            x_source (torch.Tensor): the source text data tensor.\n",
    "                x_source.shape should be (batch, vectorizer.max_source_length)\n",
    "            x_source_lengths torch.Tensor): the length of the sequences in x_source\n",
    "            target_sequence (torch.Tensor): the target text data tensor\n",
    "        Returns:\n",
    "            decoded_states (torch.Tensor): prediction vectors at each output step\n",
    "        \"\"\"\n",
    "        encoder_state, final_hidden_states = self.encoder(x_source, x_source_lengths)\n",
    "        decoded_states = self.decoder(\n",
    "            encoder_state=encoder_state,\n",
    "            initial_hidden_state=final_hidden_states,\n",
    "            target_sequence=target_sequence,\n",
    "        )\n",
    "        return decoded_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5860052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"def normalize_sizes(y_pred, y_true):\\n    if len(y_pred.size()) == 3:\\n        y_pred = y_pred.contiguous().view(-1, y_pred.size(2))\\n    if len(y_true.size()) == 2:\\n        y_true = y_true.contiguous().view(-1)\\n    return y_pred, y_true\\n\\n\\ndef compute_accuracy(y_pred, y_true, mask_index):\\n    y_pred, y_true = normalize_sizes(y_pred, y_true)\\n    _, y_pred_indices = y_pred.max(dim=1)\\n    correct_indices = torch.eq(y_pred_indices, y_true).float()\\n    valid_indices = torch.ne(y_true, mask_index).float()\\n    n_correct = (correct_indices * valid_indices).sum().item()\\n    n_valid = valid_indices.sum().item()\\n\\n    return n_correct / n_valid * 100\\n\\n\\ndef sequence_loss(y_pred, y_true, mask_index):\\n    y_pred, y_true = normalize_sizes(y_pred, y_true)\\n    return F.cross_entropy(y_pred, y_true, ignore_index=mask_index)\";\n",
       "                var nbb_formatted_code = \"def normalize_sizes(y_pred, y_true):\\n    if len(y_pred.size()) == 3:\\n        y_pred = y_pred.contiguous().view(-1, y_pred.size(2))\\n    if len(y_true.size()) == 2:\\n        y_true = y_true.contiguous().view(-1)\\n    return y_pred, y_true\\n\\n\\ndef compute_accuracy(y_pred, y_true, mask_index):\\n    y_pred, y_true = normalize_sizes(y_pred, y_true)\\n    _, y_pred_indices = y_pred.max(dim=1)\\n    correct_indices = torch.eq(y_pred_indices, y_true).float()\\n    valid_indices = torch.ne(y_true, mask_index).float()\\n    n_correct = (correct_indices * valid_indices).sum().item()\\n    n_valid = valid_indices.sum().item()\\n\\n    return n_correct / n_valid * 100\\n\\n\\ndef sequence_loss(y_pred, y_true, mask_index):\\n    y_pred, y_true = normalize_sizes(y_pred, y_true)\\n    return F.cross_entropy(y_pred, y_true, ignore_index=mask_index)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def normalize_sizes(y_pred, y_true):\n",
    "    if len(y_pred.size()) == 3:\n",
    "        y_pred = y_pred.contiguous().view(-1, y_pred.size(2))\n",
    "    if len(y_true.size()) == 2:\n",
    "        y_true = y_true.contiguous().view(-1)\n",
    "    return y_pred, y_true\n",
    "\n",
    "\n",
    "def compute_accuracy(y_pred, y_true, mask_index):\n",
    "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    correct_indices = torch.eq(y_pred_indices, y_true).float()\n",
    "    valid_indices = torch.ne(y_true, mask_index).float()\n",
    "    n_correct = (correct_indices * valid_indices).sum().item()\n",
    "    n_valid = valid_indices.sum().item()\n",
    "\n",
    "    return n_correct / n_valid * 100\n",
    "\n",
    "\n",
    "def sequence_loss(y_pred, y_true, mask_index):\n",
    "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "    return F.cross_entropy(y_pred, y_true, ignore_index=mask_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b64c1517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"args = Namespace(\\n    # Data and path information\\n    dataset_csv=\\\"../data/nmt/simplest_eng_fra.csv\\\",\\n    vectorizer_file=\\\"vectorizer.json\\\",\\n    model_state_file=\\\"model.pth\\\",\\n    save_dir=\\\"models/chapter08/nmt_luong_no_sampling\\\",\\n    # Model hyper parameter\\n    source_embedding_size=64,\\n    target_embedding_size=64,\\n    encoding_size=64,\\n    # Training hyper parameter\\n    num_epochs=100,\\n    learning_rate=5e-4,\\n    batch_size=64,\\n    seed=1337,\\n    early_stopping_criteria=5,\\n    # Runtime hyper parameter\\n    cuda=True,\\n    catch_keyboard_interrupt=True,\\n    reload_from_files=False,\\n    expand_filepaths_to_save_dir=True,\\n)\\n\\nif not torch.cuda.is_available():\\n    args.cuda = False\\n\\nargs.device = torch.device(\\\"cuda\\\" if args.cuda else \\\"cpu\\\")\\n\\nprint(\\\"Using CUDA: {}\\\".format(args.cuda))\\n\\n\\nif args.expand_filepaths_to_save_dir:\\n    args.vectorizer_file = os.path.join(args.save_dir, args.vectorizer_file)\\n\\n    args.model_state_file = os.path.join(args.save_dir, args.model_state_file)\\n\\n# Set seed for reproducibility\\nutils.set_seed_everywhere(args.seed, args.cuda)\\n\\n# handle dirs\\nutils.handle_dirs(args.save_dir)\";\n",
       "                var nbb_formatted_code = \"args = Namespace(\\n    # Data and path information\\n    dataset_csv=\\\"../data/nmt/simplest_eng_fra.csv\\\",\\n    vectorizer_file=\\\"vectorizer.json\\\",\\n    model_state_file=\\\"model.pth\\\",\\n    save_dir=\\\"models/chapter08/nmt_luong_no_sampling\\\",\\n    # Model hyper parameter\\n    source_embedding_size=64,\\n    target_embedding_size=64,\\n    encoding_size=64,\\n    # Training hyper parameter\\n    num_epochs=100,\\n    learning_rate=5e-4,\\n    batch_size=64,\\n    seed=1337,\\n    early_stopping_criteria=5,\\n    # Runtime hyper parameter\\n    cuda=True,\\n    catch_keyboard_interrupt=True,\\n    reload_from_files=False,\\n    expand_filepaths_to_save_dir=True,\\n)\\n\\nif not torch.cuda.is_available():\\n    args.cuda = False\\n\\nargs.device = torch.device(\\\"cuda\\\" if args.cuda else \\\"cpu\\\")\\n\\nprint(\\\"Using CUDA: {}\\\".format(args.cuda))\\n\\n\\nif args.expand_filepaths_to_save_dir:\\n    args.vectorizer_file = os.path.join(args.save_dir, args.vectorizer_file)\\n\\n    args.model_state_file = os.path.join(args.save_dir, args.model_state_file)\\n\\n# Set seed for reproducibility\\nutils.set_seed_everywhere(args.seed, args.cuda)\\n\\n# handle dirs\\nutils.handle_dirs(args.save_dir)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    # Data and path information\n",
    "    dataset_csv=\"../data/nmt/simplest_eng_fra.csv\",\n",
    "    vectorizer_file=\"vectorizer.json\",\n",
    "    model_state_file=\"model.pth\",\n",
    "    save_dir=\"models/chapter08/nmt_luong_no_sampling\",\n",
    "    # Model hyper parameter\n",
    "    source_embedding_size=64,\n",
    "    target_embedding_size=64,\n",
    "    encoding_size=64,\n",
    "    # Training hyper parameter\n",
    "    num_epochs=100,\n",
    "    learning_rate=5e-4,\n",
    "    batch_size=64,\n",
    "    seed=1337,\n",
    "    early_stopping_criteria=5,\n",
    "    # Runtime hyper parameter\n",
    "    cuda=True,\n",
    "    catch_keyboard_interrupt=True,\n",
    "    reload_from_files=False,\n",
    "    expand_filepaths_to_save_dir=True,\n",
    ")\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "\n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "\n",
    "\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.vectorizer_file = os.path.join(args.save_dir, args.vectorizer_file)\n",
    "\n",
    "    args.model_state_file = os.path.join(args.save_dir, args.model_state_file)\n",
    "\n",
    "# Set seed for reproducibility\n",
    "utils.set_seed_everywhere(args.seed, args.cuda)\n",
    "\n",
    "# handle dirs\n",
    "utils.handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39199d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMTModel(\n",
      "  (encoder): NMTEncoder(\n",
      "    (source_embedding): Embedding(3025, 64, padding_idx=0)\n",
      "    (birnn): GRU(64, 64, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (decoder): NMTDecoder(\n",
      "    (target_embedding): Embedding(4911, 64, padding_idx=0)\n",
      "    (gru_cell): GRUCell(192, 128)\n",
      "    (hidden_map): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (classifier): Linear(in_features=256, out_features=4911, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"dataset = NMTDataset.load_dataset_and_make_vectorizer(args.dataset_csv)\\ndataset.save_vectorizer(args.vectorizer_file)\\nvectorizer = dataset.get_vectorizer()\\nmodel = NMTModel(\\n    source_vocab_size=len(vectorizer.source_vocab),\\n    source_embedding_size=args.source_embedding_size,\\n    target_vocab_size=len(vectorizer.target_vocab),\\n    target_embedding_size=args.target_embedding_size,\\n    encoding_size=args.encoding_size,\\n    target_bos_index=vectorizer.target_vocab.begin_seq_index,\\n)\\nprint(model)\\nmodel = model.to(args.device)\\noptimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(\\n    optimizer=optimizer, mode=\\\"min\\\", factor=0.5, patience=1\\n)\";\n",
       "                var nbb_formatted_code = \"dataset = NMTDataset.load_dataset_and_make_vectorizer(args.dataset_csv)\\ndataset.save_vectorizer(args.vectorizer_file)\\nvectorizer = dataset.get_vectorizer()\\nmodel = NMTModel(\\n    source_vocab_size=len(vectorizer.source_vocab),\\n    source_embedding_size=args.source_embedding_size,\\n    target_vocab_size=len(vectorizer.target_vocab),\\n    target_embedding_size=args.target_embedding_size,\\n    encoding_size=args.encoding_size,\\n    target_bos_index=vectorizer.target_vocab.begin_seq_index,\\n)\\nprint(model)\\nmodel = model.to(args.device)\\noptimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(\\n    optimizer=optimizer, mode=\\\"min\\\", factor=0.5, patience=1\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = NMTDataset.load_dataset_and_make_vectorizer(args.dataset_csv)\n",
    "dataset.save_vectorizer(args.vectorizer_file)\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "model = NMTModel(\n",
    "    source_vocab_size=len(vectorizer.source_vocab),\n",
    "    source_embedding_size=args.source_embedding_size,\n",
    "    target_vocab_size=len(vectorizer.target_vocab),\n",
    "    target_embedding_size=args.target_embedding_size,\n",
    "    encoding_size=args.encoding_size,\n",
    "    target_bos_index=vectorizer.target_vocab.begin_seq_index,\n",
    ")\n",
    "print(model)\n",
    "model = model.to(args.device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer=optimizer, mode=\"min\", factor=0.5, patience=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bedf8ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0adf4212c8a4fb1b060e9adf05b925c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Routine:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56cc33c27f92414dae714b7d2283c6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=train:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d587340ff25343ad978037b037749b38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=val:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ Split=train, Size=9138 ============\n",
      "============ Split=val, Size=1955 ============\n",
      "--------------- 0th Epoch Stats---------------\n",
      "Training Loss=5.142246467966428, Training Accuracy=31.828060422727447\n",
      "Validation Loss=4.053562482198078, Validation Accuracy=41.74359698957813.\n",
      "------------------------------------------------------------\n",
      "--------------- 10th Epoch Stats---------------\n",
      "Training Loss=2.1405728921084344, Training Accuracy=57.85677331040806\n",
      "Validation Loss=2.705363154411316, Validation Accuracy=56.411841792220386.\n",
      "------------------------------------------------------------\n",
      "--------------- 20th Epoch Stats---------------\n",
      "Training Loss=1.4635745110646103, Training Accuracy=66.35018309044487\n",
      "Validation Loss=2.5676170110702516, Validation Accuracy=59.34158479695269.\n",
      "------------------------------------------------------------\n",
      "--------------- 30th Epoch Stats---------------\n",
      "Training Loss=1.2246064627674258, Training Accuracy=70.64503503800213\n",
      "Validation Loss=2.5546172698338827, Validation Accuracy=60.43889661554259.\n",
      "------------------------------------------------------------\n",
      "--------------- 40th Epoch Stats---------------\n",
      "Training Loss=1.2140049367723336, Training Accuracy=70.78180249930992\n",
      "Validation Loss=2.561919768651326, Validation Accuracy=60.40036278628064.\n",
      "------------------------------------------------------------\n",
      "--------------- 50th Epoch Stats---------------\n",
      "Training Loss=1.2140450452415033, Training Accuracy=70.891229066963\n",
      "Validation Loss=2.560079582532247, Validation Accuracy=60.66377671724369.\n",
      "------------------------------------------------------------\n",
      "--------------- 60th Epoch Stats---------------\n",
      "Training Loss=1.2107043908515442, Training Accuracy=70.98509725269265\n",
      "Validation Loss=2.5599972883860267, Validation Accuracy=60.392941158333855.\n",
      "------------------------------------------------------------\n",
      "--------------- 70th Epoch Stats---------------\n",
      "Training Loss=1.2108737364621234, Training Accuracy=70.94400860300867\n",
      "Validation Loss=2.554336714744568, Validation Accuracy=60.67028146195439.\n",
      "------------------------------------------------------------\n",
      "--------------- 80th Epoch Stats---------------\n",
      "Training Loss=1.2120698564489123, Training Accuracy=70.98715652273914\n",
      "Validation Loss=2.5592311700185135, Validation Accuracy=60.30654114363086.\n",
      "------------------------------------------------------------\n",
      "--------------- 90th Epoch Stats---------------\n",
      "Training Loss=1.2151754834282567, Training Accuracy=70.83529382257224\n",
      "Validation Loss=2.5625034491221106, Validation Accuracy=60.60847759046372.\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"model = model.to(args.device)\\nmask_index = vectorizer.target_vocab.mask_index\\ntrain_state = utils.make_train_state(args)\\nepoch_bar = notebook.tqdm(desc=\\\"Training Routine\\\", total=args.num_epochs, position=0)\\ndataset.set_split(\\\"train\\\")\\ntrain_bar = notebook.tqdm(\\n    desc=\\\"split=train\\\",\\n    total=dataset.get_num_batches(args.batch_size),\\n    position=1,\\n    leave=True,\\n)\\ndataset.set_split(\\\"val\\\")\\nval_bar = notebook.tqdm(\\n    desc=\\\"split=val\\\",\\n    total=dataset.get_num_batches(args.batch_size),\\n    position=1,\\n    leave=True,\\n)\\n\\nfor epoch_index in range(args.num_epochs):\\n    train_state[\\\"epoch_index\\\"] = epoch_index\\n    # Iterate Over Training Dataset\\n    # Setup: Batch Generator, set loss & acc to 0, set train mode on\\n    dataset.set_split(\\\"train\\\")\\n    if epoch_index == 0:\\n        print(\\n            f\\\"============ Split={dataset._train_split}, Size={len(dataset)} ============\\\"\\n        )\\n    batch_generator = generate_nmt_batches(\\n        dataset, batch_size=args.batch_size, device=args.device\\n    )\\n    training_running_loss, training_running_acc = 0.0, 0.0\\n    model.train()\\n\\n    for batch_index, batch_dict in enumerate(batch_generator):\\n        # 5 Step Training Routine\\n\\n        # Step 1. Zero the Gradients\\n        optimizer.zero_grad()\\n\\n        # Step 2. Compute the gradients\\n        y_pred = model(\\n            batch_dict[\\\"x_source\\\"],\\n            batch_dict[\\\"x_source_length\\\"],\\n            batch_dict[\\\"x_target\\\"],\\n        )\\n\\n        # Step 3. Compute the Output\\n        loss = sequence_loss(y_pred, batch_dict[\\\"y_target\\\"], mask_index=mask_index)\\n\\n        # Step 4. Use loss to produce gradients\\n        loss.backward()\\n\\n        # Step 5. Use Optimizer to take gradient step\\n        optimizer.step()\\n\\n        # Compute the running loss and accuracy\\n        loss_batch = loss.item()\\n        training_running_loss += (loss_batch - training_running_loss) / (\\n            batch_index + 1\\n        )\\n        acc_batch = compute_accuracy(y_pred, batch_dict[\\\"y_target\\\"], mask_index)\\n        training_running_acc += (acc_batch - training_running_acc) / (batch_index + 1)\\n\\n        # Update the bar\\n        train_bar.set_postfix(\\n            loss=training_running_loss, acc=training_running_acc, epoch=epoch_index\\n        )\\n        train_bar.update()\\n    train_state[\\\"train_loss\\\"].append(training_running_loss)\\n    train_state[\\\"train_acc\\\"].append(training_running_acc)\\n\\n    # Iterate Over Val Dataset\\n    # Setup: Batch Generator, set loss and acc to 0, set eval mode on\\n    dataset.set_split(\\\"val\\\")\\n    val_running_loss, val_running_acc = 0.0, 0.0\\n    if len(dataset) > 0:\\n        if epoch_index == 0:\\n            print(\\n                f\\\"============ Split={dataset._train_split}, Size={len(dataset)} ============\\\"\\n            )\\n        batch_generator = utils.generate_batches(\\n            dataset, batch_size=args.batch_size, device=args.device\\n        )\\n        model.eval()\\n\\n        for batch_index, batch_dict in enumerate(batch_generator):\\n            # Step 1. Compute the Output\\n            y_pred = model(\\n                batch_dict[\\\"x_source\\\"],\\n                batch_dict[\\\"x_source_length\\\"],\\n                batch_dict[\\\"x_target\\\"],\\n            )\\n\\n            # Step 2. Compute the loss\\n            loss = sequence_loss(y_pred, batch_dict[\\\"y_target\\\"], mask_index)\\n            loss_batch = loss.item()\\n            val_running_loss += (loss_batch - val_running_loss) / (batch_index + 1)\\n\\n            # Step 3. Compute the accuracy\\n            acc_batch = compute_accuracy(y_pred, batch_dict[\\\"y_target\\\"], mask_index)\\n            val_running_acc += (acc_batch - val_running_acc) / (batch_index + 1)\\n            val_bar.set_postfix(\\n                loss=val_running_loss, acc=val_running_acc, epoch=epoch_index\\n            )\\n            val_bar.update()\\n        train_state[\\\"val_loss\\\"].append(val_running_loss)\\n        train_state[\\\"val_acc\\\"].append(val_running_acc)\\n        scheduler.step(train_state[\\\"val_loss\\\"][-1])\\n    else:\\n        if epoch_index == 0:\\n            print(f\\\"============ Skipping Validation Pass ============\\\")\\n        train_state[\\\"val_loss\\\"].append(val_running_loss)\\n        train_state[\\\"val_acc\\\"].append(val_running_acc)\\n        scheduler.step(train_state[\\\"train_loss\\\"][-1])\\n    train_state = utils.update_train_state(\\n        args=args, model=model, train_state=train_state\\n    )\\n\\n    train_bar.n, val_bar.n = 0, 0\\n    epoch_bar.update()\\n\\n    if train_state[\\\"stop_early\\\"]:\\n        print(\\\"Stopping early....\\\")\\n        break\\n\\n    if epoch_index % 10 == 0:\\n        print(\\n            f\\\"--------------- {epoch_index}th Epoch Stats---------------\\\\n\\\"\\n            f\\\"Training Loss={training_running_loss}, \\\"\\n            f\\\"Training Accuracy={training_running_acc}\\\\n\\\"\\n            f\\\"Validation Loss={val_running_loss}, \\\"\\n            f\\\"Validation Accuracy={val_running_acc}.\\\\n\\\"\\n            \\\"------------------------------------------------------------\\\"\\n        )\";\n",
       "                var nbb_formatted_code = \"model = model.to(args.device)\\nmask_index = vectorizer.target_vocab.mask_index\\ntrain_state = utils.make_train_state(args)\\nepoch_bar = notebook.tqdm(desc=\\\"Training Routine\\\", total=args.num_epochs, position=0)\\ndataset.set_split(\\\"train\\\")\\ntrain_bar = notebook.tqdm(\\n    desc=\\\"split=train\\\",\\n    total=dataset.get_num_batches(args.batch_size),\\n    position=1,\\n    leave=True,\\n)\\ndataset.set_split(\\\"val\\\")\\nval_bar = notebook.tqdm(\\n    desc=\\\"split=val\\\",\\n    total=dataset.get_num_batches(args.batch_size),\\n    position=1,\\n    leave=True,\\n)\\n\\nfor epoch_index in range(args.num_epochs):\\n    train_state[\\\"epoch_index\\\"] = epoch_index\\n    # Iterate Over Training Dataset\\n    # Setup: Batch Generator, set loss & acc to 0, set train mode on\\n    dataset.set_split(\\\"train\\\")\\n    if epoch_index == 0:\\n        print(\\n            f\\\"============ Split={dataset._train_split}, Size={len(dataset)} ============\\\"\\n        )\\n    batch_generator = generate_nmt_batches(\\n        dataset, batch_size=args.batch_size, device=args.device\\n    )\\n    training_running_loss, training_running_acc = 0.0, 0.0\\n    model.train()\\n\\n    for batch_index, batch_dict in enumerate(batch_generator):\\n        # 5 Step Training Routine\\n\\n        # Step 1. Zero the Gradients\\n        optimizer.zero_grad()\\n\\n        # Step 2. Compute the gradients\\n        y_pred = model(\\n            batch_dict[\\\"x_source\\\"],\\n            batch_dict[\\\"x_source_length\\\"],\\n            batch_dict[\\\"x_target\\\"],\\n        )\\n\\n        # Step 3. Compute the Output\\n        loss = sequence_loss(y_pred, batch_dict[\\\"y_target\\\"], mask_index=mask_index)\\n\\n        # Step 4. Use loss to produce gradients\\n        loss.backward()\\n\\n        # Step 5. Use Optimizer to take gradient step\\n        optimizer.step()\\n\\n        # Compute the running loss and accuracy\\n        loss_batch = loss.item()\\n        training_running_loss += (loss_batch - training_running_loss) / (\\n            batch_index + 1\\n        )\\n        acc_batch = compute_accuracy(y_pred, batch_dict[\\\"y_target\\\"], mask_index)\\n        training_running_acc += (acc_batch - training_running_acc) / (batch_index + 1)\\n\\n        # Update the bar\\n        train_bar.set_postfix(\\n            loss=training_running_loss, acc=training_running_acc, epoch=epoch_index\\n        )\\n        train_bar.update()\\n    train_state[\\\"train_loss\\\"].append(training_running_loss)\\n    train_state[\\\"train_acc\\\"].append(training_running_acc)\\n\\n    # Iterate Over Val Dataset\\n    # Setup: Batch Generator, set loss and acc to 0, set eval mode on\\n    dataset.set_split(\\\"val\\\")\\n    val_running_loss, val_running_acc = 0.0, 0.0\\n    if len(dataset) > 0:\\n        if epoch_index == 0:\\n            print(\\n                f\\\"============ Split={dataset._train_split}, Size={len(dataset)} ============\\\"\\n            )\\n        batch_generator = utils.generate_batches(\\n            dataset, batch_size=args.batch_size, device=args.device\\n        )\\n        model.eval()\\n\\n        for batch_index, batch_dict in enumerate(batch_generator):\\n            # Step 1. Compute the Output\\n            y_pred = model(\\n                batch_dict[\\\"x_source\\\"],\\n                batch_dict[\\\"x_source_length\\\"],\\n                batch_dict[\\\"x_target\\\"],\\n            )\\n\\n            # Step 2. Compute the loss\\n            loss = sequence_loss(y_pred, batch_dict[\\\"y_target\\\"], mask_index)\\n            loss_batch = loss.item()\\n            val_running_loss += (loss_batch - val_running_loss) / (batch_index + 1)\\n\\n            # Step 3. Compute the accuracy\\n            acc_batch = compute_accuracy(y_pred, batch_dict[\\\"y_target\\\"], mask_index)\\n            val_running_acc += (acc_batch - val_running_acc) / (batch_index + 1)\\n            val_bar.set_postfix(\\n                loss=val_running_loss, acc=val_running_acc, epoch=epoch_index\\n            )\\n            val_bar.update()\\n        train_state[\\\"val_loss\\\"].append(val_running_loss)\\n        train_state[\\\"val_acc\\\"].append(val_running_acc)\\n        scheduler.step(train_state[\\\"val_loss\\\"][-1])\\n    else:\\n        if epoch_index == 0:\\n            print(f\\\"============ Skipping Validation Pass ============\\\")\\n        train_state[\\\"val_loss\\\"].append(val_running_loss)\\n        train_state[\\\"val_acc\\\"].append(val_running_acc)\\n        scheduler.step(train_state[\\\"train_loss\\\"][-1])\\n    train_state = utils.update_train_state(\\n        args=args, model=model, train_state=train_state\\n    )\\n\\n    train_bar.n, val_bar.n = 0, 0\\n    epoch_bar.update()\\n\\n    if train_state[\\\"stop_early\\\"]:\\n        print(\\\"Stopping early....\\\")\\n        break\\n\\n    if epoch_index % 10 == 0:\\n        print(\\n            f\\\"--------------- {epoch_index}th Epoch Stats---------------\\\\n\\\"\\n            f\\\"Training Loss={training_running_loss}, \\\"\\n            f\\\"Training Accuracy={training_running_acc}\\\\n\\\"\\n            f\\\"Validation Loss={val_running_loss}, \\\"\\n            f\\\"Validation Accuracy={val_running_acc}.\\\\n\\\"\\n            \\\"------------------------------------------------------------\\\"\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = model.to(args.device)\n",
    "mask_index = vectorizer.target_vocab.mask_index\n",
    "train_state = utils.make_train_state(args)\n",
    "epoch_bar = notebook.tqdm(desc=\"Training Routine\", total=args.num_epochs, position=0)\n",
    "dataset.set_split(\"train\")\n",
    "train_bar = notebook.tqdm(\n",
    "    desc=\"split=train\",\n",
    "    total=dataset.get_num_batches(args.batch_size),\n",
    "    position=1,\n",
    "    leave=True,\n",
    ")\n",
    "dataset.set_split(\"val\")\n",
    "val_bar = notebook.tqdm(\n",
    "    desc=\"split=val\",\n",
    "    total=dataset.get_num_batches(args.batch_size),\n",
    "    position=1,\n",
    "    leave=True,\n",
    ")\n",
    "\n",
    "for epoch_index in range(args.num_epochs):\n",
    "    train_state[\"epoch_index\"] = epoch_index\n",
    "    # Iterate Over Training Dataset\n",
    "    # Setup: Batch Generator, set loss & acc to 0, set train mode on\n",
    "    dataset.set_split(\"train\")\n",
    "    if epoch_index == 0:\n",
    "        print(\n",
    "            f\"============ Split={dataset._train_split}, Size={len(dataset)} ============\"\n",
    "        )\n",
    "    batch_generator = generate_nmt_batches(\n",
    "        dataset, batch_size=args.batch_size, device=args.device\n",
    "    )\n",
    "    training_running_loss, training_running_acc = 0.0, 0.0\n",
    "    model.train()\n",
    "\n",
    "    for batch_index, batch_dict in enumerate(batch_generator):\n",
    "        # 5 Step Training Routine\n",
    "\n",
    "        # Step 1. Zero the Gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Step 2. Compute the gradients\n",
    "        y_pred = model(\n",
    "            batch_dict[\"x_source\"],\n",
    "            batch_dict[\"x_source_length\"],\n",
    "            batch_dict[\"x_target\"],\n",
    "        )\n",
    "\n",
    "        # Step 3. Compute the Output\n",
    "        loss = sequence_loss(y_pred, batch_dict[\"y_target\"], mask_index=mask_index)\n",
    "\n",
    "        # Step 4. Use loss to produce gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Step 5. Use Optimizer to take gradient step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute the running loss and accuracy\n",
    "        loss_batch = loss.item()\n",
    "        training_running_loss += (loss_batch - training_running_loss) / (\n",
    "            batch_index + 1\n",
    "        )\n",
    "        acc_batch = compute_accuracy(y_pred, batch_dict[\"y_target\"], mask_index)\n",
    "        training_running_acc += (acc_batch - training_running_acc) / (batch_index + 1)\n",
    "\n",
    "        # Update the bar\n",
    "        train_bar.set_postfix(\n",
    "            loss=training_running_loss, acc=training_running_acc, epoch=epoch_index\n",
    "        )\n",
    "        train_bar.update()\n",
    "    train_state[\"train_loss\"].append(training_running_loss)\n",
    "    train_state[\"train_acc\"].append(training_running_acc)\n",
    "\n",
    "    # Iterate Over Val Dataset\n",
    "    # Setup: Batch Generator, set loss and acc to 0, set eval mode on\n",
    "    dataset.set_split(\"val\")\n",
    "    val_running_loss, val_running_acc = 0.0, 0.0\n",
    "    if len(dataset) > 0:\n",
    "        if epoch_index == 0:\n",
    "            print(\n",
    "                f\"============ Split={dataset._train_split}, Size={len(dataset)} ============\"\n",
    "            )\n",
    "        batch_generator = utils.generate_batches(\n",
    "            dataset, batch_size=args.batch_size, device=args.device\n",
    "        )\n",
    "        model.eval()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # Step 1. Compute the Output\n",
    "            y_pred = model(\n",
    "                batch_dict[\"x_source\"],\n",
    "                batch_dict[\"x_source_length\"],\n",
    "                batch_dict[\"x_target\"],\n",
    "            )\n",
    "\n",
    "            # Step 2. Compute the loss\n",
    "            loss = sequence_loss(y_pred, batch_dict[\"y_target\"], mask_index)\n",
    "            loss_batch = loss.item()\n",
    "            val_running_loss += (loss_batch - val_running_loss) / (batch_index + 1)\n",
    "\n",
    "            # Step 3. Compute the accuracy\n",
    "            acc_batch = compute_accuracy(y_pred, batch_dict[\"y_target\"], mask_index)\n",
    "            val_running_acc += (acc_batch - val_running_acc) / (batch_index + 1)\n",
    "            val_bar.set_postfix(\n",
    "                loss=val_running_loss, acc=val_running_acc, epoch=epoch_index\n",
    "            )\n",
    "            val_bar.update()\n",
    "        train_state[\"val_loss\"].append(val_running_loss)\n",
    "        train_state[\"val_acc\"].append(val_running_acc)\n",
    "        scheduler.step(train_state[\"val_loss\"][-1])\n",
    "    else:\n",
    "        if epoch_index == 0:\n",
    "            print(f\"============ Skipping Validation Pass ============\")\n",
    "        train_state[\"val_loss\"].append(val_running_loss)\n",
    "        train_state[\"val_acc\"].append(val_running_acc)\n",
    "        scheduler.step(train_state[\"train_loss\"][-1])\n",
    "    train_state = utils.update_train_state(\n",
    "        args=args, model=model, train_state=train_state\n",
    "    )\n",
    "\n",
    "    train_bar.n, val_bar.n = 0, 0\n",
    "    epoch_bar.update()\n",
    "\n",
    "    if train_state[\"stop_early\"]:\n",
    "        print(\"Stopping early....\")\n",
    "        break\n",
    "\n",
    "    if epoch_index % 10 == 0:\n",
    "        print(\n",
    "            f\"--------------- {epoch_index}th Epoch Stats---------------\\n\"\n",
    "            f\"Training Loss={training_running_loss}, \"\n",
    "            f\"Training Accuracy={training_running_acc}\\n\"\n",
    "            f\"Validation Loss={val_running_loss}, \"\n",
    "            f\"Validation Accuracy={val_running_acc}.\\n\"\n",
    "            \"------------------------------------------------------------\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814897b3",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e74ad486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"from nltk.translate import bleu_score\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\nchencherry = bleu_score.SmoothingFunction()\";\n",
       "                var nbb_formatted_code = \"from nltk.translate import bleu_score\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\nchencherry = bleu_score.SmoothingFunction()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.translate import bleu_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "chencherry = bleu_score.SmoothingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0db76244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"def sentences_from_indices(indices, vocab, strict=True, return_string=True):\\n    ignore_indices = set([vocab.mask_index, vocab.begin_seq_index, vocab_end_seq_index])\\n    out = []\\n    for index in indices:\\n        if index == vocab.begin_seq_index and strict:\\n            continue\\n        elif index == vocab.end_seq_index and strict:\\n            break\\n        else:\\n            out.append(vocab.lookup_index(index))\\n    if return_string:\\n        return \\\" \\\".join(out)\\n    else:\\n        return out\\n\\n\\ndef get_source_sentence(vectorizer, batch_dict, index):\\n    indices = batch_dict[\\\"x_source\\\"][index].cpu().data.numpy()\\n    vocab = vectorizer.source_vocab\\n    return sentence_from_indices(indices, vocab)\\n\\n\\ndef get_true_sentence(vectorizer, batch_dict, index):\\n    return sentence_from_indices(\\n        batch_dict[\\\"y_target\\\"].cpu().data.numpy()[index], vectorizer.target_vocab\\n    )\\n\\n\\ndef get_sampled_sentence(vectorizer, batch_dict, index):\\n    y_pred = model(\\n        x_source=batch_dict[\\\"x_source\\\"],\\n        x_source_lengths=batch_dict[\\\"x_source_length\\\"],\\n        target_sequence=batch_dict[\\\"x_target\\\"],\\n    )\\n    return sentence_from_indices(\\n        torch.max(y_pred, dim=2)[1].cpu().data.numpy()[index], vectorizer.target_vocab\\n    )\\n\\n\\ndef get_all_sentences(vectorizer, batch_dict, index):\\n    return {\\n        \\\"source\\\": get_source_sentence(vectorizer, batch_dict, index),\\n        \\\"truth\\\": get_true_sentence(vectorizer, batch_dict, index),\\n        \\\"sampled\\\": get_sampled_sentence(vectorizer, batch_dict, index),\\n    }\\n\\n\\ndef sentence_from_indices(indices, vocab, strict=True, return_string=True):\\n    ignore_indices = set([vocab.mask_index, vocab.begin_seq_index, vocab.end_seq_index])\\n    out = []\\n    for index in indices:\\n        if index == vocab.begin_seq_index and strict:\\n            continue\\n        elif index == vocab.end_seq_index and strict:\\n            return \\\" \\\".join(out)\\n        else:\\n            out.append(vocab.lookup_index(index))\\n    return \\\" \\\".join(out)\";\n",
       "                var nbb_formatted_code = \"def sentences_from_indices(indices, vocab, strict=True, return_string=True):\\n    ignore_indices = set([vocab.mask_index, vocab.begin_seq_index, vocab_end_seq_index])\\n    out = []\\n    for index in indices:\\n        if index == vocab.begin_seq_index and strict:\\n            continue\\n        elif index == vocab.end_seq_index and strict:\\n            break\\n        else:\\n            out.append(vocab.lookup_index(index))\\n    if return_string:\\n        return \\\" \\\".join(out)\\n    else:\\n        return out\\n\\n\\ndef get_source_sentence(vectorizer, batch_dict, index):\\n    indices = batch_dict[\\\"x_source\\\"][index].cpu().data.numpy()\\n    vocab = vectorizer.source_vocab\\n    return sentence_from_indices(indices, vocab)\\n\\n\\ndef get_true_sentence(vectorizer, batch_dict, index):\\n    return sentence_from_indices(\\n        batch_dict[\\\"y_target\\\"].cpu().data.numpy()[index], vectorizer.target_vocab\\n    )\\n\\n\\ndef get_sampled_sentence(vectorizer, batch_dict, index):\\n    y_pred = model(\\n        x_source=batch_dict[\\\"x_source\\\"],\\n        x_source_lengths=batch_dict[\\\"x_source_length\\\"],\\n        target_sequence=batch_dict[\\\"x_target\\\"],\\n    )\\n    return sentence_from_indices(\\n        torch.max(y_pred, dim=2)[1].cpu().data.numpy()[index], vectorizer.target_vocab\\n    )\\n\\n\\ndef get_all_sentences(vectorizer, batch_dict, index):\\n    return {\\n        \\\"source\\\": get_source_sentence(vectorizer, batch_dict, index),\\n        \\\"truth\\\": get_true_sentence(vectorizer, batch_dict, index),\\n        \\\"sampled\\\": get_sampled_sentence(vectorizer, batch_dict, index),\\n    }\\n\\n\\ndef sentence_from_indices(indices, vocab, strict=True, return_string=True):\\n    ignore_indices = set([vocab.mask_index, vocab.begin_seq_index, vocab.end_seq_index])\\n    out = []\\n    for index in indices:\\n        if index == vocab.begin_seq_index and strict:\\n            continue\\n        elif index == vocab.end_seq_index and strict:\\n            return \\\" \\\".join(out)\\n        else:\\n            out.append(vocab.lookup_index(index))\\n    return \\\" \\\".join(out)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sentences_from_indices(indices, vocab, strict=True, return_string=True):\n",
    "    ignore_indices = set([vocab.mask_index, vocab.begin_seq_index, vocab_end_seq_index])\n",
    "    out = []\n",
    "    for index in indices:\n",
    "        if index == vocab.begin_seq_index and strict:\n",
    "            continue\n",
    "        elif index == vocab.end_seq_index and strict:\n",
    "            break\n",
    "        else:\n",
    "            out.append(vocab.lookup_index(index))\n",
    "    if return_string:\n",
    "        return \" \".join(out)\n",
    "    else:\n",
    "        return out\n",
    "\n",
    "\n",
    "def get_source_sentence(vectorizer, batch_dict, index):\n",
    "    indices = batch_dict[\"x_source\"][index].cpu().data.numpy()\n",
    "    vocab = vectorizer.source_vocab\n",
    "    return sentence_from_indices(indices, vocab)\n",
    "\n",
    "\n",
    "def get_true_sentence(vectorizer, batch_dict, index):\n",
    "    return sentence_from_indices(\n",
    "        batch_dict[\"y_target\"].cpu().data.numpy()[index], vectorizer.target_vocab\n",
    "    )\n",
    "\n",
    "\n",
    "def get_sampled_sentence(vectorizer, batch_dict, index):\n",
    "    y_pred = model(\n",
    "        x_source=batch_dict[\"x_source\"],\n",
    "        x_source_lengths=batch_dict[\"x_source_length\"],\n",
    "        target_sequence=batch_dict[\"x_target\"],\n",
    "    )\n",
    "    return sentence_from_indices(\n",
    "        torch.max(y_pred, dim=2)[1].cpu().data.numpy()[index], vectorizer.target_vocab\n",
    "    )\n",
    "\n",
    "\n",
    "def get_all_sentences(vectorizer, batch_dict, index):\n",
    "    return {\n",
    "        \"source\": get_source_sentence(vectorizer, batch_dict, index),\n",
    "        \"truth\": get_true_sentence(vectorizer, batch_dict, index),\n",
    "        \"sampled\": get_sampled_sentence(vectorizer, batch_dict, index),\n",
    "    }\n",
    "\n",
    "\n",
    "def sentence_from_indices(indices, vocab, strict=True, return_string=True):\n",
    "    ignore_indices = set([vocab.mask_index, vocab.begin_seq_index, vocab.end_seq_index])\n",
    "    out = []\n",
    "    for index in indices:\n",
    "        if index == vocab.begin_seq_index and strict:\n",
    "            continue\n",
    "        elif index == vocab.end_seq_index and strict:\n",
    "            return \" \".join(out)\n",
    "        else:\n",
    "            out.append(vocab.lookup_index(index))\n",
    "    return \" \".join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cee8326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"class NMTSampler:\\n    def __init__(self, vectorizer, model):\\n        self.vectorizer = vectorizer\\n        self.model = model\\n\\n    def apply_to_batch(self, batch_dict):\\n        self._last_batch = batch_dict\\n        y_pred = self.model(\\n            x_source=batch_dict[\\\"x_source\\\"],\\n            x_source_lengths=batch_dict[\\\"x_source_length\\\"],\\n            target_sequence=batch_dict[\\\"x_target\\\"],\\n        )\\n        self._last_batch[\\\"y_pred\\\"] = y_pred\\n        attention_batched = np.stack(self.model.decoder._cached_p_attn).transpose(\\n            1, 0, 2\\n        )\\n        self._last_batch[\\\"attention\\\"] = attention_batched\\n\\n    def _get_source_sentence(self, index, return_string=True):\\n        indices = self._last_batch[\\\"x_source\\\"][index].cpu().detach().numpy()\\n        vocab = self.vectorizer.source_vocab\\n        return sentence_from_indices(indices, vocab, return_string=return_string)\\n\\n    def _get_reference_sentence(self, index, return_string=True):\\n        indices = self._last_batch[\\\"y_target\\\"][index].cpu().detach().numpy()\\n        vocab = self.vectorizer.target_vocab\\n        return sentence_from_indices(indices, vocab, return_string=return_string)\\n\\n    def _get_sampled_sentence(self, index, return_string=True):\\n        _, all_indices = torch.max(self._last_batch[\\\"y_pred\\\"], dim=2)\\n        sentence_indices = all_indices[index].cpu().detach().numpy()\\n        vocab = self.vectorizer.target_vocab\\n        return sentence_from_indices(\\n            sentence_indices, vocab, return_string=return_string\\n        )\\n\\n    def get_ith_item(self, index, return_string=True):\\n        output = {\\n            \\\"source\\\": self._get_source_sentence(index, return_string=return_string),\\n            \\\"reference\\\": self._get_reference_sentence(\\n                index, return_string=return_string\\n            ),\\n            \\\"sampled\\\": self._get_sampled_sentence(index, return_string=return_string),\\n            \\\"attention\\\": self._last_batch[\\\"attention\\\"][index],\\n        }\\n        reference = output[\\\"reference\\\"]\\n        hypothesis = output[\\\"sampled\\\"]\\n        if not return_string:\\n            reference = \\\" \\\".join(reference)\\n            hypothesis = \\\" \\\".join(hypothesis)\\n        output[\\\"bleu-4\\\"] = bleu_score.sentence_bleu(\\n            references=[reference],\\n            hypothesis=hypothesis,\\n            smoothing_function=chencherry.method1,\\n        )\\n        return output\";\n",
       "                var nbb_formatted_code = \"class NMTSampler:\\n    def __init__(self, vectorizer, model):\\n        self.vectorizer = vectorizer\\n        self.model = model\\n\\n    def apply_to_batch(self, batch_dict):\\n        self._last_batch = batch_dict\\n        y_pred = self.model(\\n            x_source=batch_dict[\\\"x_source\\\"],\\n            x_source_lengths=batch_dict[\\\"x_source_length\\\"],\\n            target_sequence=batch_dict[\\\"x_target\\\"],\\n        )\\n        self._last_batch[\\\"y_pred\\\"] = y_pred\\n        attention_batched = np.stack(self.model.decoder._cached_p_attn).transpose(\\n            1, 0, 2\\n        )\\n        self._last_batch[\\\"attention\\\"] = attention_batched\\n\\n    def _get_source_sentence(self, index, return_string=True):\\n        indices = self._last_batch[\\\"x_source\\\"][index].cpu().detach().numpy()\\n        vocab = self.vectorizer.source_vocab\\n        return sentence_from_indices(indices, vocab, return_string=return_string)\\n\\n    def _get_reference_sentence(self, index, return_string=True):\\n        indices = self._last_batch[\\\"y_target\\\"][index].cpu().detach().numpy()\\n        vocab = self.vectorizer.target_vocab\\n        return sentence_from_indices(indices, vocab, return_string=return_string)\\n\\n    def _get_sampled_sentence(self, index, return_string=True):\\n        _, all_indices = torch.max(self._last_batch[\\\"y_pred\\\"], dim=2)\\n        sentence_indices = all_indices[index].cpu().detach().numpy()\\n        vocab = self.vectorizer.target_vocab\\n        return sentence_from_indices(\\n            sentence_indices, vocab, return_string=return_string\\n        )\\n\\n    def get_ith_item(self, index, return_string=True):\\n        output = {\\n            \\\"source\\\": self._get_source_sentence(index, return_string=return_string),\\n            \\\"reference\\\": self._get_reference_sentence(\\n                index, return_string=return_string\\n            ),\\n            \\\"sampled\\\": self._get_sampled_sentence(index, return_string=return_string),\\n            \\\"attention\\\": self._last_batch[\\\"attention\\\"][index],\\n        }\\n        reference = output[\\\"reference\\\"]\\n        hypothesis = output[\\\"sampled\\\"]\\n        if not return_string:\\n            reference = \\\" \\\".join(reference)\\n            hypothesis = \\\" \\\".join(hypothesis)\\n        output[\\\"bleu-4\\\"] = bleu_score.sentence_bleu(\\n            references=[reference],\\n            hypothesis=hypothesis,\\n            smoothing_function=chencherry.method1,\\n        )\\n        return output\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NMTSampler:\n",
    "    def __init__(self, vectorizer, model):\n",
    "        self.vectorizer = vectorizer\n",
    "        self.model = model\n",
    "\n",
    "    def apply_to_batch(self, batch_dict):\n",
    "        self._last_batch = batch_dict\n",
    "        y_pred = self.model(\n",
    "            x_source=batch_dict[\"x_source\"],\n",
    "            x_source_lengths=batch_dict[\"x_source_length\"],\n",
    "            target_sequence=batch_dict[\"x_target\"],\n",
    "        )\n",
    "        self._last_batch[\"y_pred\"] = y_pred\n",
    "        attention_batched = np.stack(self.model.decoder._cached_p_attn).transpose(\n",
    "            1, 0, 2\n",
    "        )\n",
    "        self._last_batch[\"attention\"] = attention_batched\n",
    "\n",
    "    def _get_source_sentence(self, index, return_string=True):\n",
    "        indices = self._last_batch[\"x_source\"][index].cpu().detach().numpy()\n",
    "        vocab = self.vectorizer.source_vocab\n",
    "        return sentence_from_indices(indices, vocab, return_string=return_string)\n",
    "\n",
    "    def _get_reference_sentence(self, index, return_string=True):\n",
    "        indices = self._last_batch[\"y_target\"][index].cpu().detach().numpy()\n",
    "        vocab = self.vectorizer.target_vocab\n",
    "        return sentence_from_indices(indices, vocab, return_string=return_string)\n",
    "\n",
    "    def _get_sampled_sentence(self, index, return_string=True):\n",
    "        _, all_indices = torch.max(self._last_batch[\"y_pred\"], dim=2)\n",
    "        sentence_indices = all_indices[index].cpu().detach().numpy()\n",
    "        vocab = self.vectorizer.target_vocab\n",
    "        return sentence_from_indices(\n",
    "            sentence_indices, vocab, return_string=return_string\n",
    "        )\n",
    "\n",
    "    def get_ith_item(self, index, return_string=True):\n",
    "        output = {\n",
    "            \"source\": self._get_source_sentence(index, return_string=return_string),\n",
    "            \"reference\": self._get_reference_sentence(\n",
    "                index, return_string=return_string\n",
    "            ),\n",
    "            \"sampled\": self._get_sampled_sentence(index, return_string=return_string),\n",
    "            \"attention\": self._last_batch[\"attention\"][index],\n",
    "        }\n",
    "        reference = output[\"reference\"]\n",
    "        hypothesis = output[\"sampled\"]\n",
    "        if not return_string:\n",
    "            reference = \" \".join(reference)\n",
    "            hypothesis = \" \".join(hypothesis)\n",
    "        output[\"bleu-4\"] = bleu_score.sentence_bleu(\n",
    "            references=[reference],\n",
    "            hypothesis=hypothesis,\n",
    "            smoothing_function=chencherry.method1,\n",
    "        )\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b43cbff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"model = model.eval().to(args.device)\\nsampler = NMTSampler(vectorizer, model)\\n\\ndataset.set_split(\\\"test\\\")\\nbatch_generator = generate_nmt_batches(\\n    dataset, batch_size=args.batch_size, device=args.device\\n)\\ntest_results = []\\nfor batch_dict in batch_generator:\\n    sampler.apply_to_batch(batch_dict)\\n    for i in range(args.batch_size):\\n        test_results.append(sampler.get_ith_item(i, False))\";\n",
       "                var nbb_formatted_code = \"model = model.eval().to(args.device)\\nsampler = NMTSampler(vectorizer, model)\\n\\ndataset.set_split(\\\"test\\\")\\nbatch_generator = generate_nmt_batches(\\n    dataset, batch_size=args.batch_size, device=args.device\\n)\\ntest_results = []\\nfor batch_dict in batch_generator:\\n    sampler.apply_to_batch(batch_dict)\\n    for i in range(args.batch_size):\\n        test_results.append(sampler.get_ith_item(i, False))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = model.eval().to(args.device)\n",
    "sampler = NMTSampler(vectorizer, model)\n",
    "\n",
    "dataset.set_split(\"test\")\n",
    "batch_generator = generate_nmt_batches(\n",
    "    dataset, batch_size=args.batch_size, device=args.device\n",
    ")\n",
    "test_results = []\n",
    "for batch_dict in batch_generator:\n",
    "    sampler.apply_to_batch(batch_dict)\n",
    "    for i in range(args.batch_size):\n",
    "        test_results.append(sampler.get_ith_item(i, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c53b12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6097948772678232, 0.6142899197697873)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"plt.hist(\\n    [\\n        r['bleu-4']\\n        for r in test_results\\n    ],\\n    bins=100\\n);\\nnp.mean(\\n    [\\n        r['bleu-4']\\n        for r in test_results\\n    ],\\n), np.median(\\n    [\\n        r['bleu-4']\\n        for r in test_results\\n    ],\\n)\";\n",
       "                var nbb_formatted_code = \"plt.hist([r[\\\"bleu-4\\\"] for r in test_results], bins=100)\\nnp.mean([r[\\\"bleu-4\\\"] for r in test_results],), np.median(\\n    [r[\\\"bleu-4\\\"] for r in test_results],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([r[\"bleu-4\"] for r in test_results], bins=100)\n",
    "np.mean([r[\"bleu-4\"] for r in test_results],), np.median(\n",
    "    [r[\"bleu-4\"] for r in test_results],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3afd725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"dataset.set_split('val')\\nbatch_generator = generate_nmt_batches(\\n    dataset,\\n    batch_size=args.batch_size,\\n    device=args.device\\n)\\nbatch_dict = next(batch_generator)\\n\\nmodel = model.eval().to(args.device)\\nsampler = NMTSampler(vectorizer, model)\\nsampler.apply_to_batch(batch_dict)\";\n",
       "                var nbb_formatted_code = \"dataset.set_split(\\\"val\\\")\\nbatch_generator = generate_nmt_batches(\\n    dataset, batch_size=args.batch_size, device=args.device\\n)\\nbatch_dict = next(batch_generator)\\n\\nmodel = model.eval().to(args.device)\\nsampler = NMTSampler(vectorizer, model)\\nsampler.apply_to_batch(batch_dict)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.set_split(\"val\")\n",
    "batch_generator = generate_nmt_batches(\n",
    "    dataset, batch_size=args.batch_size, device=args.device\n",
    ")\n",
    "batch_dict = next(batch_generator)\n",
    "\n",
    "model = model.eval().to(args.device)\n",
    "sampler = NMTSampler(vectorizer, model)\n",
    "sampler.apply_to_batch(batch_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f23c10c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"all_results = []\\nfor i in range(args.batch_size):\\n    all_results.append(sampler.get_ith_item(i, False))\\n\\ntop_results = [x for x in all_results if x[\\\"bleu-4\\\"] > 0.1]\\nprint(len(top_results))\";\n",
       "                var nbb_formatted_code = \"all_results = []\\nfor i in range(args.batch_size):\\n    all_results.append(sampler.get_ith_item(i, False))\\n\\ntop_results = [x for x in all_results if x[\\\"bleu-4\\\"] > 0.1]\\nprint(len(top_results))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_results = []\n",
    "for i in range(args.batch_size):\n",
    "    all_results.append(sampler.get_ith_item(i, False))\n",
    "\n",
    "top_results = [x for x in all_results if x[\"bleu-4\"] > 0.1]\n",
    "print(len(top_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "737983a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': \"i 'm not flexible enough to sit in the <UNK> position .\",\n",
       " 'truth': \"je ne suis pas assez <UNK> pour m'asseoir dans la position du <UNK> .\",\n",
       " 'sampled': 'je ne suis pas sr bonne de le des la maison . . .'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"results = get_all_sentences(vectorizer, batch_dict, 1)\\nresults\";\n",
       "                var nbb_formatted_code = \"results = get_all_sentences(vectorizer, batch_dict, 1)\\nresults\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = get_all_sentences(vectorizer, batch_dict, 1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e34be2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "je suis en route pour le visite  la bonne  me coul la . 15\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (25), usually from a call to set_ticks, does not match the number of ticklabels (15).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-c81273889a68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_yticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mylabs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sampled\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sampled\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sampled\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target Sentence\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Source Sentence\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp-with-pytorch/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp-with-pytorch/lib/python3.8/site-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m                 \u001b[0;34m\"parameter will become keyword-only %(removal)s.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m                 name=name, obj_type=f\"parameter of {func.__name__}()\")\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp-with-pytorch/lib/python3.8/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_set_ticklabels\u001b[0;34m(self, labels, fontdict, minor, **kwargs)\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfontdict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp-with-pytorch/lib/python3.8/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mset_ticklabels\u001b[0;34m(self, ticklabels, minor, **kwargs)\u001b[0m\n\u001b[1;32m   1709\u001b[0m             \u001b[0;31m# remove all tick labels, so only error for > 0 ticklabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1711\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1712\u001b[0m                     \u001b[0;34m\"The number of FixedLocator locations\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1713\u001b[0m                     \u001b[0;34mf\" ({len(locator.locs)}), usually from a call to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The number of FixedLocator locations (25), usually from a call to set_ticks, does not match the number of ticklabels (15)."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"for sample in top_results:\\n    plt.figure()\\n    target_len = len(sample[\\\"sampled\\\"])\\n    source_len = len(sample[\\\"source\\\"])\\n\\n    attention_matrix = sample[\\\"attention\\\"][\\n        :target_len, : source_len + 2\\n    ].transpose()  # [::-1]\\n    ax = sns.heatmap(attention_matrix, center=0.0)\\n    # print(sample[\\\"source\\\"])\\n    ylabs = \\\"<BOS> \\\" + sample[\\\"source\\\"] + \\\" <EOS>\\\"\\n    ax.set_yticklabels(ylabs.split(\\\" \\\"), rotation=0)\\n    print(sample[\\\"sampled\\\"], len(sample[\\\"sampled\\\"].split(\\\" \\\")))\\n    ax.set_xticklabels(sample[\\\"sampled\\\"].split(\\\" \\\"), rotation=90)\\n    ax.set_xlabel(\\\"Target Sentence\\\")\\n    ax.set_ylabel(\\\"Source Sentence\\\\n\\\\n\\\")\";\n",
       "                var nbb_formatted_code = \"for sample in top_results:\\n    plt.figure()\\n    target_len = len(sample[\\\"sampled\\\"])\\n    source_len = len(sample[\\\"source\\\"])\\n\\n    attention_matrix = sample[\\\"attention\\\"][\\n        :target_len, : source_len + 2\\n    ].transpose()  # [::-1]\\n    ax = sns.heatmap(attention_matrix, center=0.0)\\n    # print(sample[\\\"source\\\"])\\n    ylabs = \\\"<BOS> \\\" + sample[\\\"source\\\"] + \\\" <EOS>\\\"\\n    ax.set_yticklabels(ylabs.split(\\\" \\\"), rotation=0)\\n    print(sample[\\\"sampled\\\"], len(sample[\\\"sampled\\\"].split(\\\" \\\")))\\n    ax.set_xticklabels(sample[\\\"sampled\\\"].split(\\\" \\\"), rotation=90)\\n    ax.set_xlabel(\\\"Target Sentence\\\")\\n    ax.set_ylabel(\\\"Source Sentence\\\\n\\\\n\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for sample in top_results:\n",
    "    plt.figure()\n",
    "    target_len = len(sample[\"sampled\"])\n",
    "    source_len = len(sample[\"source\"])\n",
    "\n",
    "    attention_matrix = sample[\"attention\"][\n",
    "        :target_len, : source_len + 2\n",
    "    ].transpose()  # [::-1]\n",
    "    ax = sns.heatmap(attention_matrix, center=0.0)\n",
    "    # print(sample[\"source\"])\n",
    "    ylabs = \"<BOS> \" + sample[\"source\"] + \" <EOS>\"\n",
    "    ax.set_yticks()\n",
    "    ax.set_yticklabels(ylabs.split(\" \"), rotation=0)\n",
    "    print(sample[\"sampled\"], len(sample[\"sampled\"].split(\" \")))\n",
    "    ax.set_xticklabels(sample[\"sampled\"].split(\" \"), rotation=90)\n",
    "    ax.set_xlabel(\"Target Sentence\")\n",
    "    ax.set_ylabel(\"Source Sentence\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6ba3221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': \"i 'm not flexible enough to sit in the <UNK> position .\",\n",
       " 'truth': \"je ne suis pas assez <UNK> pour m'asseoir dans la position du <UNK> .\",\n",
       " 'sampled': 'je ne suis pas sr du de le du la maison . . .'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"results = get_all_sentences(vectorizer, batch_dict, 1)\\nresults\";\n",
       "                var nbb_formatted_code = \"results = get_all_sentences(vectorizer, batch_dict, 1)\\nresults\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefbdd97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84d0159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d83541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b67893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Advanced Sequence Modeling for Natural Language Processing",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
